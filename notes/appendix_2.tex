\section{Theoretical Background} \label{sec:appendix1}


In the first two sections of this Appendix, we provide a standard textbook review of axiomatic probability theory and formulate the non-linear stochastic filtering problem (see for example, \cite{bain2009,karlin1975}).  Following Chapter 10 of \cite{bain2009}, we describe a standard particle filter algorithm using an axiomatic approach to probability theory and we re-state well-known conditions for its convergence. In the last section, we describe the qslam framework in the language of stochastic filtering of sections two and three of this Appendix, and we outline the proof of convergence for the qslam particle filtering algorithm.

\subsection{Axiomatic Probability Theory}

\begin{defn} \label{defn:pspace} 
	
	A probability space is denoted by the triple ($\samplespace{{}}$, $ \family{{}}$, $\measure{{}}{\cdot}$). Denote the sample space, $\samplespace{{}}$, as the set of events that constitute all possible outcomes of an experiment. All possible subsets of $\samplespace{{}}$ constitutes a family or a collection of events, $\family{{}}$. An event $A$ occurs if the outcome corresponding to $A$, $\omega \in \samplespace{{}}$  is also an element of $A$, $\omega\in A$. The probability measure. $\measure{{}}{\cdot}$ is a function defined on $\family{{}}$ satisfying:
	
	\begin{thmprop} 
		\item \label{defn:pspace:prop1} $ 0 = \measure{{}}{\emptyset} \leq \measure{{}}{A} \leq \measure{{}}{\samplespace{{}}} = 1, \quad \forall A \in \family{{}}$
		\item \label{defn:pspace:prop2} $\measure{{}}{A_1 \cup A_2} = \measure{{}}{A_1}  + \measure{{}}{A_2}    - \measure{{}}{A_1 \cap A_2}, \quad \forall A_i \in \family{{}}, i =1,2 $
		\item \label{defn:pspace:prop3} $\measure{{}}{\cup_{i=1}^{\infty} A_i} = \sum_{i=1}^{\infty} \measure{{}}{A_i}$ if $A_i$ are mutually disjoint $A_i \cap A_j = \emptyset, i \neq j$
	\end{thmprop}
\end{defn}

In the case that it is not feasible to consider all possible subsets of $\samplespace{{}}$, then one can define a \ofield{}, a collection of events that enable us to define a probability measure satisfying \cref{defn:pspace}\ref{defn:pspace:prop1}-\ref{defn:pspace:prop3}.

\begin{defn}
	\label{defn:ofield}
	A collection of subsets, $\ofieldA{}$ of  $\samplespace{{}}$ is called an \ofield{} if the set satisfies:
	\begin{thmprop}
		\item \label{defn:ofield:prop1} $\emptyset, \samplespace{{}} \in \ofieldA{}$
		\item \label{defn:ofield:prop2} $A^c \in \ofieldA{}$ whenever $A \in \ofieldA{}$
		\item \label{defn:ofield:prop3} $\cup_{i=1}^{\infty}A_i \in \ofieldA{}$ whenever $A_i \in \ofieldA{}$, $i=1,2, \hdots $
	\end{thmprop}
\end{defn} As a consequence, an \ofield{} maintains all possible unions and intersections of events within the field, making it possible to define a probability measure while considering a set smaller than $\family{{}}$. 

A random variable $X$ is a real valued function defined on $\samplespace{{}}$. The probability distribution function of $X$ is the probability that a set of outcomes  in $\samplespace{{}}$ take the value of $X$. By definition, $X$ has a probability distribution function on the collection of all possible subsets, $\family{{}}$. For an arbitrary \ofield{}, $\ofieldA{} \in \family{{}}$, the random variable $X$ must be $\ofieldA{}$-measurable for the probability distribution function of $X$ to have any meaning. 

\begin{defn}
	$X$ is measurable with respect to any \ofield{} of subsets of $\samplespace{{}}$, denoted $\ofieldA{}$, if :
	\begin{align}
	\{\omega: a < X(\omega) \leq b \} \in \ofieldA{}, \quad \forall a < b \in \mathbb{R}
	\end{align}
	Then the probability distribution function of a random variable $X$ that is $\ofieldA{}$-measurable is:
	\begin{align}
	\pr(a < X \leq b ) = \measure{{}}{\{\omega: a < X(\omega) \leq b \} }
	\end{align}
\end{defn}

\begin{defn}
	The \ofield{} generated by $X$ is the smallest  \ofield{} with respect to which $X$ is measurable, denoted as $\ofieldgen{X}$. More generally, if $\{X(t), t \in T \}$ is a family of random variables parameterised by $t$, then $\ofieldgen{\{X(t), t \in T \}}$ generated by $X$ is the smallest \ofield{} with respect to which every random variable $X(t)$ is measurable. 
\end{defn}

The \ofield{} generated by intervals on the real line are called \ofield{}s of Borel sets, which are frequently used to define continuous random variables.
\begin{defn}
	A Borel $\sigma$-algebra on the real line  is the smallest \ofield{} containing every interval of the form $(a, b]$.  Alternatively, it is the \ofield{} generated by the identity function $f(x) =x, x \in  (-\infty, +\infty)$. A real valued function of a real variable is said to be Borel-measurable if it is measurable with respect to the \ofield{} of Borel sets. 
\end{defn}

We now summarise results for conditional expectations and conditional probability of a function with respect to an \ofield{}. Since random variables are real-valued, measurable functions defined on $\samplespace{{}}$ , we define the state space for any random variable and  sets of functions on this state space to enable concise notation. 

\begin{defn} Define $\mathbb{S}$ a {\color{red} complete, separable metric} space and $\mathcal{S} \equiv \ofieldgen{\mathbb{S}}$ as the associated Borel $\sigma$-algebra generated by $\mathbb{S}$. On ($\mathbb{S}$, $\mathcal{S}$), we define:
	\begin{align}
	C(\mathbb{S}) &: \text{the space of real {\color{red}  continuous} functions on $\mathbb{S}$} \\
	M(\mathbb{S}) &: \text{ the space of $\mathcal{S}$-measurable functions on } \mathbb{S} \\ % \to \mathbb{R} \\
	B(\mathbb{S}) &: \text{ the space of {\color{red} bounded} $\mathcal{S}$-measurable functions on } \mathbb{S} \\ % \to \mathbb{R} \\
	C_b(\mathbb{S}) &: \text{ the space of bounded countinuous functions on } \mathbb{S} \\ % \to \mathbb{R} \\
	P(\mathbb{S}) &: \text{ the space of probability measures  on } (\mathbb{S}, \mathcal{S}) \text{ such that $\mu \in P(\mathbb{S})$ satisfies $\mu(\mathbb{S})=1$ }
	\end{align}
\end{defn}

\begin{defn}
	Let ($\samplespace{{}}$, $ \family{{}}$, $\measure{{}}{\cdot}$) be a probability space and let $\mathcal{G} \subset \family{{}}$  be a sub- $\sigma$-algebra of $\family{{}}$. Let $\xi$ be an $\family{{}}$-measurable random variable. The conditional expectation of $\xi$ given $\mathcal{G}$ is defined as a $\mathcal{G}$-measurable random variable, $\ex{\xi | \mathcal{G}}$ satisfying $\mathbb{P}$- {\color{red}almost surely} (a.s.):
	\begin{align}
	 \ex{\xi Z} & = \ex{\ex{\xi | \mathcal{G}}Z}, \quad Z \in B(\mathbb{G}) \\
	 \ex{\alpha_1 \xi_1 + \alpha_2 \xi_2} & = \alpha_1 \ex{\xi_1}  + \alpha_2 \ex{\xi_2}  \quad \alpha_i \in \mathbb{R}, \xi_i \text{ are $\family{{}}$-measurable}, i = 1,2 \\
	 \xi \geq 0 & \implies \ex{\xi | \mathcal{G}} \geq 0  \\
	 0 \leq \xi_n \nearrow \xi & \implies \ex{\xi_n | \mathcal{G}} \nearrow \ex{\xi | \mathcal{G}} \\
	\ex{X|\mathcal{A}} & = \ex{\ex{X|\mathcal{G}}|\mathcal{A}}, \mathrm{if} \mathcal{A} \subset \mathcal{G} \\
 	\ex{\xi Z | \mathcal{G}} & = Z \ex{\xi | \mathcal{G}} \quad Z \in B(\mathbb{G}) \\
 	\ex{ Z | \mathcal{G}} & =Z, \quad Z \in M(\mathbb{G}), \ex{|Z|} < \infty
	\end{align} 	
Alternatively, the conditional expectation of a set $A \in \mathcal{G}$ with respect to the $\sigma$-algebra of $\mathcal{G} \subset \family{{}}$ can also be defined in terms of the indicator function of the set $A$
\begin{align}
\int_{\mathcal{F}}  \xi(\omega) I_A (\omega) d\mathbb{P} &= \int_{\mathcal{F}}  \ex{\xi | \mathcal{G}}(\omega) I_A(\omega) d\mathbb{P} \\
\implies \int_{\mathcal{G}}  \xi(\omega) d\mathbb{P} &= \int_{\mathcal{G}}  \ex{\xi | \mathcal{G}}(\omega) d\mathbb{P} \\
I_A(\omega) &:= \begin{cases}
1, \omega \in A \\
0, \omega \notin A \\
\end{cases}, \omega \in \samplespace{{}}, \forall A\in \mathcal{G}
\end{align}
Under certain conditions (Th. A.3. of \cite{bain2009}), it is possible to define a conditional probability of a set $F \in \family{{}}$ given $G \in  \mathcal{G} \subset \family{{}}$:
\begin{align}
\measure{{}}{F \cap G} &= \int_{G \in \mathcal{G}}  \measure{{}}{F | \mathcal{G}} d\mathbb{P}\quad \forall F \in \family{{}},  G \in \mathcal{G} \label{eqn:def:condprob}  \\
\measure{{}}{F | \mathcal{G}} & := \ex{I_F | \mathcal{G}}  \\
\measure{{}}{F \cap G} &: = \int_{\mathcal{G}}  I_F (\omega) d\mathbb{P} 
\end{align} where $I_F$ denotes the indicator function for the set $F$. 
The two definitions of conditional expectation are equivalent and this can be seen by setting $Z \equiv I_A$ to get: $\ex{\xi I_A} = \ex{\ex{\xi | \mathcal{G}} I_A}, \quad I_A \in B(\mathbb{G})$. For $Z = \mathbb{I}$ (identity), we recover the total law of probability as $ \ex{\xi} = \ex{\ex{\xi | \mathcal{G}}}.$ 
\end{defn} 
 
In filtering problems, it is often assumed that the Bayesian posterior distribution corresponds to a random measure over a probability space to which an inference procedure converges. We use axiomatic probability theory to consider a space of random measures  and we define convergence theorems for measure-valued random variables. 
\begin{lemma} [A.10, Bain \& Crisan, 2009]
	Let ($\samplespace{{}}$, $ \family{{}}$, $\measure{{}}{\cdot}$) be a probability space and let $(\mu^n)_{n=1}^\infty \in P$ be a sequence of random measures and let $\mu \in P$ be another measure valued random variable. We define two types of convergence:
	\begin{align}
	&\lim_{n \to \infty} \ex{ |\mu^nf - \mu f| } = 0, \quad \forall f \in C_b \\
	&\lim_{n \to \infty} \mu^n = \mu, \quad \mathbb{P}-\mathrm{a.s.} 
	\end{align}The first limit is convergence in expectation.  The second limit refers to pointwise convergence. 
	
	Since  $(\mu^n)_{n=1}^\infty$ is a sequence of random probability measures, it is bounded above by one, namely  $\mu^n(1) = 1 \forall n$. Then by the {\color{red} dominated convergence theorem}, and for all $f$ continuously bounded functions:
	\begin{align}
	\lim_{n \to \infty} \mu^n = \mu, \quad \mathbb{P}-\mathrm{a.s.} \implies \lim_{n \to \infty} \ex{ |\mu^nf - \mu f| } = 0 
	\end{align}
		
	Without proof, we state that:
	\begin{align}
	\lim_{n \to \infty} \ex{ |\mu^nf - \mu f| } = 0  &\implies \exists n(m) s.t. \lim_{m \to \infty} \mu^{n(m)} = \mu, \quad \mathbb{P}-\mathrm{a.s.}  \\
	\lim_{n \to \infty} \ex{ |\mu^nf - \mu f| } \leq \frac{c_f}{\sqrt{n}}, f \in \mathcal{M} &\implies  \lim_{m \to \infty} \mu^{m^3} = \mu \\
	\end{align} where $\mathcal{M} $ is a space of finite measures, $c_f$ is a constant.
	Further, assume a positive constant $p>1$, then either of the following conditions:
	\begin{align}
	&\lim_{n \to \infty} \ex{ |\mu^nf - \mu f|^{2p} }  \leq \frac{c_f}{n^p} \\
	&\lim_{n \to \infty} \ex{ d(\mu^n, \mu)^{2p} }  \leq \frac{c}{n^p} 
	\end{align}
	imply that these exists an $\epsilon \in [0, 0.5 - 1/2p]$ such that:
	\begin{align}
	&|\mu^nf - \mu f| \leq \frac{c_{\epsilon, (f)}}{ n^\epsilon} \\
	&\lim_{n \to \infty} \mu^n = \mu, \quad \mathbb{P}-\mathrm{a.s.} 
	\end{align} Here, $d(\cdot, \cdot)$ is any metric that generates a {\color{red} weak topology} on $\mathcal{M} $ and quantifies the closeness between any two random processes.
\end{lemma}
	
	

\subsection{Non Linear Filtering Theory}
In this section, we formally define the filtering problem of inferring a true state $X$ from observations $Y$. \\

Let $X = \{X_t, t = 1, 2, \hdots \}, X \in \mathbb{R}^d$ be a stochastic process defined on the composite probability space $(\samplespace{X}, \family{X}, \measure{{}}{\cdot})$. Let the filtration generated by the process $X$ as:
\begin{align}
\mathcal{F}_{t} &:= \sigma(\{X_s, s\in[0, t]\})
\end{align} By definition, the family of random variables $\{X_s, s\in[0, t]\}$ is $\mathcal{F}_{t}$-measurable for each $t$. Further, the Borel \ofield{}s generated  are of increasing size  $\mathcal{F}_{t-1} \subset \mathcal{F}_{t} \subseteq \mathcal{F}_{X}$. 
\begin{azm}
	$X$ is Markov. ($F$, $R$ are Markov.)
\end{azm} For Markov $X$, one can write:
\begin{align}
\measure{X}{X_{t} \in A |\family{t-1}} = \measure{X}{X_{t} \in A | X_{t-1}}  \quad \forall A \in \mathcal{S}_X, \quad \forall t
\end{align}
Let the observation process $Y = \{Y_t, t= 0, 1, 2, \hdots\} $ be an $\mathbb{S}_Y$-valued stochastic process with $Y_0 = 0$ and:
\begin{align}
Y_t & := h(t, X_t) + W_t, t>0 \\
h &:  \mathbb{N} \times \mathbb{S}_X \to \mathbb{S}_Y, h \in M(\mathbb{N} \times \mathbb{S}_X )
\end{align}
\begin{azm}
The measurement noise, $W_t: \samplespace{Y} \to \mathbb{S}_Y $ are a set of mutually independent random vectors, and continuous with respect to the {\color{red} Lebesgue measure} on $\mathbb{S}_Y $. The density of $W_t$ with respect to the Lebesgue measure is $g(t, \cdot) \in B(\mathbb{S}_X)$ and $g(t, \cdot)$ a strictly positive function. 
\end{azm}
\begin{defn}
The filtering problem is to compute a random measure $\pi_t$ that is the conditional probability of  $X$ given the \ofield{} generated by the observation process $Y_{0:T}:=\{Y_0, \hdots, Y_t \}$:
\begin{align}
\pi_t(A) &:= \measure{{}}{X_t \in A | \ofieldgen{Y_{0:T}}}, \quad \forall A \in \mathcal{S}_X \\
\pi_t(A) f &= \ex{f(X_t) |  \ofieldgen{Y_{0:T}}} \quad \forall f \in B(\mathbb{S}_X), A \in \mathcal{S}_X 
\end{align} Here, $\pi_t$ is the Bayesian posterior. For a fixed realisation or a fixed path, $y_{0:t} := \{Y_0 = y_0, Y_1 =y_1, \hdots, Y_t = y_t \}$, we denote the non-random probability measure:
\begin{align}
\pi_t^{y_{0:t}} &:=  \measure{{}}{X_t \in A | Y_{0:t} =y_{0:t} }, \quad \forall A \in \mathcal{S}_X \\
\pi_t^{y_{0:t}}f  & =  \ex{f(X_t) |  Y_{0:t} =y_{0:t}} \quad \forall f \in B(\mathbb{S}_X), A \in \mathcal{S}_X 
\end{align} In shorthand, write  $\pi_t^{Y_{0:t}} \equiv \pi_t$. 
Similarly, we define a predictive distribution $p_t$ as:
\begin{align}
p_t^{y_{0:t}} & := \measure{{}}{X_t \in A | Y_{0:t-1} =y_{0:t-1} }, \quad \forall A \in \mathcal{S}_X \\
p_t^{y_{0:t}}f  & =  \ex{f(X_t) |  Y_{0:t-1} =y_{0:t-1}} \quad \forall f \in B(\mathbb{S}_X), A \in \mathcal{S}_X \\
p_t^{Y_{0:t}} & \equiv p_t
\end{align}
\end{defn}
Bayes Rule for computing the posterior distribution is generalised by the use of a \textit{projective product }in an axiomatic approach to stochastic filtering. 
\begin{defn}
	Let $\mu \in P(\mathbb{S})$ be a probability measure and $\varphi \in B(\mathbb{S})$ be a non-negative function such that $\mu(\varphi) := \int_{\mathbb{S}} \varphi(x) d\mu(x)  > 0 $. Then the \textit{projective product} is the {\color{red} set function} defined by:
	\begin{align}
	\varphi * \mu(A) :=\frac{\int_A \varphi(x) d\mu(x) }{\mu(\varphi)}
	\end{align}
	Then, $\varphi * \mu$ is a probability measure on $\mathcal{S}$.
\end{defn}
We now turn to the question of the density of a random vector. In classical probability theory, the density of a random vector is the derivative of its probability distribution function yielding a probability density (or mass) $d\mathbb{P} = p(x) dx $. We express this in terms of a Radon-Nikodym derivative as follows.

\begin{defn}
	Let $f$ be a real valued function on $[0, 1]$ that satisfies:
	\begin{align}
	|f(x) - f(y)| \leq C|x-y|, \quad \forall x,y \in [0,1], C < \infty 	
	\end{align}
	For each $n = 1, 2, \hdots$, partition the interval $[0,1]$ into a set of intervals given by $A_n$:
	\begin{align}
	A_n = \{ (k/2^n, (k+1)/2^n): k = 0, \hdots, 1, 2^n -1  \}
	\end{align}
	We define the $\mathcal{F}_n := \ofieldgen{\emptyset \cup [0,1] \cup A_n}$, $Z$ a uniformly distributed random variable on $[0, 1)$ and the sequence of random numbers $X_n$ as:
	\begin{align}
	X_n &:= 2^n \{f(k/2^n) - f((k-1)/2^n)\}, \quad \mathrm{if} (k-1)/2^n \leq Z < k/2^n \\
	&=\ex{X_\infty | \mathcal{F}_n}, \quad X_\infty:= \lim_{n \to \infty} X_n
	\end{align} The last line above comes from observing that $X_n$ is a martingale with respect to a sequence $\{Y_n = (k-1) / 2^n \}$, for $k,Z,n$ satisfying the inequalities above. Further, $X_n$ is uniformly integrable since $f$ is C-Lipschitz continuous. This allows us to invoke a martingale convergence theorem and obtain the last line (see p. 311 of 
	\cite{karlin1975}.)
	
	As $n$ and $k$ get larger, the information received about $Z=z$ increases as the lower and upper bounds of the value $Z$ get tighter. Let $B$ be the interval $[0, k/2^n)$ and $I_B$ the indicator function for $B \in \mathcal{F}_n$:
	\begin{align}
	\ex{X_nI_B} &= 2^n \ex{ \{f(k/2^n) - f((k-1)/2^n)\} I_B}, \quad n = 1, 2, \hdots, k = 1,\hdots, 2^n -1 \\
	&= 2^n \ex{f(k/2^n) - f(0)} \\
	&= f(k/2^n) - f(0) \\
	&\equiv \ex{\ex{X_\infty | \mathcal{F}_n }I_B} = \ex{X_\infty I_B} \\
	&= \int_{0}^{k/2^n} X_\infty (x) dx
	\end{align} The notation $ X_\infty (x)$ should be interpreted such that the random variable $X_\infty$ is some function of the random variable $Z$ with probability 1 (using the martingale convergence theorem for $X$).
	
	By passing the convergence to the limit, where a sequence of binary rationals approach some $Z=z \in [0,1)$, we get the Radon-Nikodym derivative of $f$:
	\begin{align}
	f(z) - f(0) = \int_{0}^{z} X_\infty (x) dx
	\end{align}
\end{defn} 
Using the concept of the Radon-Nikodym derivative, we can obtain the density of the observation vector. A continuous probability density for the observation vector enables us to extract a likelihood function and establish the continuity of the projective product (that is, the continuity of conditional probabilities analogous to Bayes Rule).
\begin{lemma}[Bain \& Crisan 2009]
	Let $\measure{Y_{s:t}}{y_{s:t}} \in P(\mathbb{S}_{Y_{s:t}})$ be the probability distribution of $Y_{s:t}$, with $\mathbb{S}_{Y_{s:t}} := (\mathbb{S}_Y)^{(t-s+1)}$  and let $\lambda$ be the Lebesque measure on $(\mathbb{S}_{Y_{s:t}}, \mathcal{S}_{Y_{s:t}})$. Then  for all $0 < s \leq t < \infty $, $\measure{Y_{s:t}}{y_{s:t}}$ is absolutely continuous with respect to $\lambda$ and its Radon-Nikodym derivative is:
	\begin{align}
	\frac{d}{d\lambda}\measure{Y_{s:t}}{y_{s:t}} = \int_{\mathbb{S}_{X_{s:t}}} \prod_{i=s}^{t} g(i, y_i - h(i, x_i)) d\measure{X_{s:t}}{x_{s:t}} \label{eqn:probdensityY}
	\end{align} where $\measure{X_{s:t}}{x_{s:t}} \in  P(\mathbb{S}_{X_{s:t}})$ is the probability distribution of $X_{s:t}$, with $\mathbb{S}_{X_{s:t}} := (\mathbb{S}_X)^{(t-s+1)}$ and $X_{s:t} = (X_s, \hdots, X_t)$. 
	
\begin{proof} We include the proof to show the usage of the density of $W_t$ as the likelihood function in axiomatic notation. Following \cite{bain2009}, the proof is summarised by, firstly, combining the state space and associated Borel sets for $Y_i, i \in [s, t]$ to obtain $(\mathbb{S}_{Y_{s:t}}, \mathcal{S}_{Y_{s:t}})$, namely, $\mathcal{S}_{Y_{s:t}} = \mathcal{S}_{Y_s} \times \hdots \times \mathcal{S}_{Y_t},  \mathcal{S}_{Y_i} \in \mathcal{S}_Y$.  Next, we reverse marginalise over the random vector of $X_{s:t}$ to obtain the probability distribution function for the observation vector as:
\begin{align}
\measure{Y_{s:t}}{Y_{s:t} \in \mathcal{S}_{Y_{s:t}}} &:= \int_{\mathcal{S}_{X_{s:t}}} \measure{{}}{Y_{s:t} \in \mathcal{S}_{Y_{s:t}} | X_{s:t} = x_{s:t}} d\measure{X_{s:t}}{x_{s:t}} 
\end{align} The definition of $\measure{{}}{Y_{s:t} \in \mathcal{S}_{Y_{s:t}} | X_{s:t} = x_{s:t}}$ follows from \cref{eqn:def:condprob} by setting $\mathcal{F} \equiv \mathcal{S}_{Y_{s:t}}$ and $\mathcal{G} \equiv \ofieldgen{\{Y_{s:t} | X_{s:t} = x_{s:t}\}}$:
\begin{align}
\measure{{}}{Y_{s:t} \in \mathcal{S}_{Y_{s:t}} | X_{s:t} = x_{s:t}} &: = \ex{ I_{Y_i \in \mathcal{S}_{Y_{s:t}}, \forall i \in [s,t]}| \ofieldgen{\{Y_{s:t} | X_{s:t} = x_{s:t}\}} } \\
& = \ex{ \prod_{i=s}^t I_{h(i, X_i) + W_i \in \mathcal{S}_{Y_{i}}}| \ofieldgen{\{Y_{s:t} | X_{s:t} = x_{s:t}\}} } \\
& = \ex{ \prod_{i=s}^t I_{h(i, x_i) + W_i \in \mathcal{S}_{Y_{i}}}} \text{ by $X_i$ indep. from $W_i$} \\
& = \prod_{i=s}^t \ex{  I_{h(i, x_i) + W_i \in \mathcal{S}_{Y_i}}}  \text{ by mutually indep. $W_i$}\\
& = \prod_{i=s}^t \int_{ \ofieldgen{W_i}} I_{h(i, x_i) + w_i \in \mathcal{S}_{Y_i}} d\measure{W_{i}}{ w_{i}} \text{ as $W_i$ is the only random variable}\\
& = \prod_{i=s}^t \int_{ \ofieldgen{W_i}} I_{h(i, x_i) + w_i \in \mathcal{S}_{Y_i}} g(i, w_i) dw_{i} \\
& = \prod_{i=s}^t \int_{ \mathcal{S}_{Y_i}} g(i, y_i - h(i, x_i))  dy_i \text{ change of variables from $w_i$ to $y_i$}
\end{align}
In a special case that the probability density function of $Y_i$ is the probability density function of $W_i$, namely, $ d\measure{W_{i}}{w_i} = g(i, w_i) dw_i = g(i, y_i - h(i, x_i ) dy_i \equiv d\measure{Y_{i}}{y_i}$, we obtain from the last line above that $\measure{{}}{Y_{i} \in dy_i | X_{i} = x_{i}} = g(i, y_i - h(i, x_i )) dy_i$.  In this specific case, $g(i, y_i - h(i, x_i ))$ is recognised as the likelihood function. 

By substitution, we let the integral over $dy_i$ be the outermost integral (invoking independence of $X$ and $W$ and hence $X$ and $Y$ at each $i$ ) to get:
\begin{align}
\measure{Y_{s:t}}{Y_{s:t} \in \mathcal{S}_{Y_{s:t}}} &:= \int_{ \mathcal{S}_{Y_i}} \int_{\mathcal{S}_{X_{s:t}}} \prod_{i=s}^t  g(i, y_i - h(i, x_i))  d\measure{X_{s:t}}{x_{s:t}}  dy_i 
\end{align} 
\end{proof} Since this holds for arbitrary $i \in [s, t]$, we conclude that for for the full set of outcomes in $\mathcal{S}_{Y_{s:t}}$:
\begin{align}
\measure{Y_{s:t}}{{y_{s:t}}} &= \int_{ \mathcal{S}_{Y_{s:t}} } \int_{\mathcal{S}_{X_{s:t}}} \prod_{i=s}^t  g(i, y_i - h(i, x_i))  d\measure{X_{s:t}}{x_{s:t}}  dy_s \hdots dy_t 
\end{align} The last line is interpreted as a Lebesgue integral, and it yields the density of the random vector $Y_{s:t}$ when differentiated with respect to the Lebsegue measure $\lambda$. 
\end{lemma} 
\begin{defn}
	The Radon-Nikodym derivative of the projective product with respect to a Lebesgue measure, $\mu$ is given by:
	\begin{align}
	\frac{d}{d\mu} (\varphi * \mu(A))(x) = \frac{d}{d\mu} \left(\frac{\int_A \varphi(x)  d\mu(x) }{\mu(\varphi)} \right)= \frac{ \varphi(x) }{\mu(\varphi)}
	\end{align} where $\mu(\varphi)$ is treated as a constant and the derivative is absolutely continuous \cite{bain2009}. 
\end{defn}
The analogue of the Bayesian posterior recursions are obtained in the following Lemma, for both a fixed observational path, and a random observation vector. These recursions give rise to a non-random and a random posterior probability measures respectively. 
\begin{lemma}[Bain \& Crisan 2009]
	For Markov $X$, the random probability measures $p_t^{Y_{0:t}} \equiv p_t, \pi_t^{Y_{0:t}} \equiv \pi_t$ satisfy the recursion relation:
	\begin{align}
	\pi_t &= g(t, y_t - h(t, x_t)) * p_t = g(t, y_t - h(t, x_t)) * K_{t-1} \pi_{t-1} \\
	p_t & :=  K_{t-1} \pi_{t-1} \\
	K_{t} &: = \measure{{}}{X_{t+1} \in A | X_t = x} \\
	&:= K_{t}(x, A) : \mathbb{S}_X \times \mathcal{S}_X \to P(\mathbb{S}_X) \times B(\mathbb{S}_X), \\
	& \quad \forall t = 0, 1, \hdots, A \in \mathcal{S}_X, x \in \mathbb{S}_X.
	\end{align} In the above, the transition kernel $K_{t} := K_{t}(x, A)$ satisfies the property that $ K_{t}(\cdot, A) \in B(\mathbb{S}_X)$ is a bounded Borel measurable function for any $A \in \mathcal{S}_X$, and $ K_{t}(x, \cdot)$ is a probability measure over all possible final states at $t+1$ if $X_t = x$. The recurrence relation is satisfied $\lambda$-almost surely, where $\lambda$ is the Lebesque measure on $(\mathcal{S}_Y)^{(t+1)}$, as in \cref{eqn:probdensityY} by setting $s=0$. 
	
	One obtains the recursion relation for the non-random measures with respect to a fixed path, $Y_{0:t}=y_{0:t}$  by letting $p_t^{Y_{0:t}} \to p_t^{y_{0:t}}$ and $\pi_t^{Y_{0:t}} \to \pi_t^{y_{0:t}}$; correspondingly this recursive relation is satisfied $\mathbb{P}_{Y_{0:t}}$ -almost surely.
	
	\begin{proof}
	As in standard Bayesian analysis, the dynamical equation exploits the Markov property of $X$ as:
	\begin{align}
p_tf(X_t)  & :=  \ex{f(X_t) |  Y_{0:t-1}}  \\
	&=  \ex{ \ex{f(X_t) |   \mathcal{F}^X_{t-1} \vee \ofieldgen{W_{0:t-1}} | \mathcal{S}_{Y_{0:t-1}} } } \\
	&=\ex{ \ex{f(X_t) |   \mathcal{F}^X_{t-1}} | \mathcal{S}_{Y_{0:t-1}} } \\
	&=\ex{ \ex{f(X_t) | X_{t-1}} | \mathcal{S}_{Y_{0:t-1}} } \\
	&=\ex{K_{t-1} f(X_{t-1}) | \mathcal{S}_{Y_{0:t-1}} } \\
   &\implies p_t f \equiv \pi_{t-1} (K_{t-1} f) \equiv K_{t-1} \pi_{t-1} \quad  \text{ for some $f$.}
	\end{align}
	The recursion using the projective product is obtained by considering the probability of the next measurement $Y_t$ and all previous knowledge about the state:
	\begin{align}
	\measure{Y_{0:t}}{y_{0:t}} &= \mathbb{P} (\{Y_t \in \mathcal{S}_{Y_t} \}\cap \{X_t \in \mathcal{S}_{X_t} \} \cap \{ Y_{0:t-1} \in \mathcal{S}_{Y_{0:t-1}}\} ) \\
	&= \int_{\mathcal{S}_{X_t} \times \mathcal{S}_{Y_{0:t-1}}} \mathbb{P} (\{Y_t \in \mathcal{S}_{Y_t} \} | X_t =x_t, Y_{0:t-1}= y_{0:t-1}) d\mathbb{P}_{X_t, Y_{0:t-1}} \\
	&= \int_{\mathcal{S}_{X_t} \times \mathcal{S}_{Y_{0:t-1}}} \mathbb{P} (\{Y_t \in \mathcal{S}_{Y_t} \} | X_t =x_t, Y_{0:t-1}= y_{0:t-1}) \mathbb{P} (X_t | Y_{0:t-1}= y_{0:t-1})  d\mathbb{P}_{ Y_{0:t-1}} \\
	&= \int_{\mathcal{S}_{A} \times \mathcal{S}_{Y_{0:t-1}}} \mathbb{P} (\{Y_t \in \mathcal{S}_{Y_t} \} | X_t =x_t, Y_{0:t-1}= y_{0:t-1}) dp_t^{y_{0:t-1}} d\mathbb{P}_{Y_{0:t-1}} \\
	&= \int_{\mathcal{S}_{A} \times \mathcal{S}_{Y_{0:t-1}}} \left(\int_{ \mathcal{S}_{Y_t}} g(t, y_t - h(t, x_t))  dy_t \right) dp_t^{y_{0:t-1}} d\mathbb{P}_{Y_{0:t-1}} \\
	&= \int_{\mathcal{S}_{Y_{0:t}}} \left(\int_{ \mathcal{S}_{A}} g(t, y_t - h(t, x_t))  dp_t^{y_{0:t-1}} \right) d\mathbb{P}_{Y_{0:t-1}} dy_t\\
	&= \int_{\mathcal{S}_{Y_{0:t}}} \left(\int_{ \mathcal{S}_{A}} g(t, y_t - h(t, x_t))  dp_t^{y_{0:t-1}} \right) \frac{d\measure{Y_{0:t}}{y_{0:t}}}{p_t(g_t^{y_t})}\\
	&= \int_{\mathcal{S}_{Y_{0:t}}} g_t^{y_t} * p_t^{y_{0:t-1}} d\measure{Y_{0:t}}{y_{0:t}} := \int_{\mathcal{S}_{Y_{0:t}}} \pi_t^{y_{0:t}}d\measure{Y_{0:t}}{y_{0:t}}
	\end{align}
	 We use the observation that $d\measure{Y_{0:t}}{\cdot} = p_t(g_t^{y_t}) d\mathbb{P}_{Y_{0:t-1}} dy_t$, where the shorthand $g_t^{y_t} \equiv g(t, y_t - h(t, x_t))$, and $p_t(g_t^{y_t}) \equiv \int_{\mathcal{S}_{X_t}} g_t^{y_t} dp_t(x)$ is used and a change of limits is applicable as $\int_{\mathcal{S}_{Y_{0:t-1}}} \measure{{}}{X_t \in A | Y_{0:t-1}} d\measure{Y_{0:t-1}}{y_{0:t-1}} = \int_{ A \times \mathcal{S}_{Y_{0:t-1}}} dp_t^{y_{0:t-1}} d\measure{Y_{0:t-1}}{y_{0:t-1}}$ for all choices of $A \in \mathcal{S}_{X_t}$. Substituting for $d\mathbb{P}_{Y_{0:t-1}} dy_t$ yields the definition of the projective product. By substituting the definition for the predictive probability distribution, $p_t$, we compare the terms inside the integrals to obtain $\pi_t = g(t, y_t - h(t, x_t)) * K_{t-1} \pi_{t-1}$. 	
	
	\end{proof}
\end{lemma}

\subsection{Particle filters approximations for $\pi_t$}

As a result of using a particle approximation to infer $\pi_t$ from data, we add another source of randomness. In section, we are interested in the random processes $\pi_t^n, p_t^n$ as approximating sequences to the true random measures $\pi_t, p_t$ , where $n$ typically denotes the number of particles used for the approximation.  The aim of this section is to re-state convergence results for standard particle filtering techniques before introducing details of our particular scheme.


\begin{theorem}[Bain \& Crisan, 2009] \label{eqn:convergence:lemma:pibar}
	Assume that for any $t\geq 0$, there exists a constant $c_t$ such that $p_tg_t \geq c_t$. Then for all $f \in B(\mathcal{S}_X)$:
	\begin{align}
	\lim_{n\to\infty} \ex{ |\pi_t^n f - \pi_t f| } &= 0  \label{eqn:conv:1}\\
	\lim_{n\to\infty} \ex{ |p_t^n f - p_t f|  } &= 0  \label{eqn:conv:2}
	\end{align} hold if and only if the following hold:
	\begin{align}
	\lim_{n\to\infty} \ex{ |\pi_0^n f - \pi_0 f|  } &= 0 \label{eqn:conv:3} \\
	\lim_{n\to\infty} \ex{ |p_t^n f - K_{t-1}\pi^{n}_{t-1} f|} &= 0 \label{eqn:conv:4}\\
	\lim_{n\to\infty} \ex{ |\pi_t f - \bar{\pi}^n_t f|} &= 0 \label{eqn:conv:5}
	\end{align} where $\bar{\pi}^n_t := g_y^{y_t} * p_t^n$ and $\bar{\pi}^n_t f =p^n_t(fg^{y_t})/p^n_t g^{y_t} $.
\end{theorem}
\begin{proof}
	Assume \cref{eqn:conv:1,eqn:conv:2} hold. Then \cref{eqn:conv:1} $\implies$ \cref{eqn:conv:3} by setting $t=0$. Similarly, \cref{eqn:conv:2} implies $\lim_{n\to\infty} \ex{ |p_t^n f - K_{t-1}\pi_{t-1} f|  } = 0$ for so-called Feller transition kernels (refer \cite{bain2009}). In our case, the transition kernels satisfy the Feller property. Then by the triangle inequality:
	\begin{align}
	|p_t^n f - K_{t-1}\pi^{n}_{t-1} f| \leq |p_t^n f - K_{t-1}\pi_{t-1} f| + | K_{t-1}\pi_{t-1} f - K_{t-1}\pi^{n}_{t-1} f|\\	
	\end{align} Taking expectations of both sides as $n \to \infty$, the two terms on the right hand side are zero from \cref{eqn:conv:1,eqn:conv:2} and we recover \cref{eqn:conv:4}. For \cref{eqn:conv:5}, require that:
	\begin{align}
	\ex{|\pi_t f - \bar{\pi}^n_t f|} \leq \ex{|\pi_t f - \pi^n_t f|} + \ex{|\pi^n_t f - \bar{\pi}^n_t f|}
	\end{align} We recover \cref{eqn:conv:5} if $\ex{|\pi^n_t f - \bar{\pi}^n_t f|} = 0$. We defer this until later in the proof below. 
	
	In the reverse direction, we obtain \cref{eqn:conv:2} by applying the triangle inequality, and \cref{eqn:conv:1} follows by induction from using \cref{eqn:conv:3} as a starting point  and \cref{eqn:conv:2,eqn:conv:4}. 
	
	Hence, we need only to show $\ex{|\pi^n_t f - \bar{\pi}^n_t f|} = 0$. To see this, we rearrange the expressions as follows:
	\begin{align}
	\pi_t f - \bar{\pi}^n_t f & = \frac{p_t(fg_t^{y_t}) }{p_t g_t^{y_t}} - \frac{p^n_t(fg_t^{y_t})}{p^n_t g^{y_t}} \\
	& = \frac{p_t(fg_t^{y_t}) }{p_t g_t^{y_t}} - \frac{p^n_t(fg_t^{y_t})}{p^n_t g^{y_t}} + \frac{p^n_t(fg_t^{y_t})}{p_t g^{y_t}} - \frac{p^n_t(fg_t^{y_t})}{p_t g^{y_t}}\\
	& = \frac{1}{p_t g_t^{y_t}} \left( p_t(fg_t^{y_t}) - p^n_t(fg_t^{y_t})\right)  + \frac{p^n_t(fg_t^{y_t})}{p_t g^{y_t}} - \frac{p^n_t(fg_t^{y_t})}{p^n_t g^{y_t}} \\
	& = \frac{1}{p_t g_t^{y_t}} \left( p_t(fg_t^{y_t}) - p^n_t(fg_t^{y_t})\right)  + \frac{p^n_t(fg_t^{y_t})}{p_t g^{y_t}p^n_t g^{y_t}} \left(p^n_t g^{y_t} - p_t g^{y_t} \right) \\
	\end{align}
	Denote $\frac{p^n_t(fg_t^{y_t})}{p^n_t g^{y_t}} \leq \parallel f_\infty \parallel$ and talking the absolute values and expectation on both sides yields:
	\begin{align}
	\ex{|\pi_t f - \bar{\pi}^n_t f|}	& \leq \ex{\frac{1}{p_t g_t^{y_t}} | p_t(fg_t^{y_t}) - p^n_t(fg_t^{y_t})|}  + \parallel f_\infty \parallel\ex{\frac{ 1}{p_t g^{y_t}} |p^n_t g^{y_t} - p_t g^{y_t} |}  \\
	& \leq \ex{\frac{1}{c_t} | p_t(fg_t^{y_t}) - p^n_t(fg_t^{y_t})|}  + \parallel f_\infty \parallel\ex{\frac{1}{c_t} |p^n_t g^{y_t} - p_t g^{y_t} |} \\
	& \leq \frac{1}{c_t} \ex{| p_t(fg_t^{y_t}) - p^n_t(fg_t^{y_t})|}  + \frac{\parallel f_\infty \parallel}{c_t} \ex{ |p^n_t g^{y_t} - p_t g^{y_t} |} 
	\end{align} Here, we invoked the assumption that there exists a constant $c_t$ such that $p_t g^{y_t} > c_t > 0$, and this allows to bring $c_t$ outside the expectation value. In the limit $n \to \infty$, both terms on the right hand side of the last line go to zero by \cref{eqn:conv:2}.
\end{proof}
A particle filter with constant number of particles $n$ and with an importance resampling weighting method consists of the following steps:
\begin{enumerate}
	\item Sample particles from an initial distribution $x_0^{(i)} \sim \pi_0$
	\item For $t > 0$
		\begin{enumerate}
			\item Sample from transition probability distribution $\bar{x}_t^{(i)} \sim K_{t-1}(x_{t-1}^{(i)}, \cdot)$.
			\item Weight particles using $w_t^{(i)} = \frac{ g(t, y_t - h(i, \bar{x}_t^{(i)})) }{\sum_i g(t, y_t - h(i, \bar{x}_t^{(i)}))}$
			\item Re-sample particles from the weighted measure  $x_t^{(i)} \sim \bar{\pi}_t^n = \sum_{i} w_t^{(i)} \delta(\bar{x}_t^{(i)})$.
			\item Reset all weights to  $w_t^{(i)} = 1/n \quad \forall i$, and denote resampled particles as $x_{t}^{(i)}$
		\end{enumerate}
\end{enumerate} For a constant number of particles, $n$, the following empirical approximations are implied by the particle filter: an initial distribution, a weighted measure (before resampling), and empirical measure (after resampling). These are defined as:
\begin{align}
\pi_0^n &:= \frac{1}{n}\sum_{i=1}^n \delta(x_0^{(i)}) \\
p_t^n &:= \frac{1}{n}\sum_{i=1}^n \delta(\bar{x}_t^{(i)}) \\
\bar{\pi}_t^n &:= \sum_{i=1}^n w_t^{(i)} \delta(\bar{x}_t^{(i)}) \\
\pi_t^n &:= \frac{1}{n}\sum_{i=1}^n \delta(x_t^{(i)}) 
\end{align}
The additional randomness introduced by the particle approximation means that we have additional filtrations generated by the algorithm:
\begin{align}
\mathcal{G}_t = \ofieldgen{x_s^{(i)}, \bar{x}_s^{(i)}, s \leq t, i = 1, \hdots, n} \\
\bar{\mathcal{G}}_t = \ofieldgen{x_s^{(i)}, \bar{x}_s^{(i)}, \bar{x}_t^{(i)}, s < t, i = 1, \hdots, n}
\end{align} Here, $\bar{\mathcal{G}}_t \subset \mathcal{G}_t$, where $\bar{\mathcal{G}}_t $ includes the weighted measure at time $t$ but excludes the resampled particles at time $t$. 

The resampling step can be thought of as a branching random process with one generation, where each parent particle is replaced by a number of offspring, given by the random number $\xi^{(i)}$. One is free to specify the type of branching mechanism, and for the scheme outlined above, we make the following assumptions that lead to a simple form of multinomial sampling and well established convergence results. 
\begin{proposition} \label{prop:banchingproperties}
	Branching mechanisms for the resampling step of a particle filter satisfy:
	\begin{enumerate}
		\item Constant particle number $n = \sum_i \xi^{(i)}$
		\item Conditional mean proportional to $w_t^{(i)}$ $\ex{ \xi^{(i)} | \bar{\mathcal{G}}_t } = n w_t^{(i)}$
		\item Conditional covariance matrix $(A^n_t)_{ij} := \ex{(\xi^{(i)} - n w_t^{(i)})^T (\xi^{(j)} - n w_t^{(j)}) | \bar{\mathcal{G}}_t }$ satisfy $q^T A^n_t q_t \leq nc_t$ for some constant $c_t$ and for any $n$ dimensional vector $q$ with entries  $|q^{(i)} |< 1$.
	\end{enumerate}
\end{proposition}

\begin{lemma} The following identities hold for the empirical distributions of a particle filter with the branching mechanism described in \cref{prop:banchingproperties}.
	\begin{align}
	\ex{p_t | \mathcal{G}_{t-1}} &= K_{t-1} \pi_{t-1}^n  \label{eqn:identity:dynamics}\\
	\pi_t^n &= \frac{1}{n}\sum_{i=1}^n \xi_t^{(i)} \delta(\bar{x}_t^{(i)})\\
	\ex{(\pi_t^n - \bar{\pi}_t^n)^2} &\leq \frac{ c_t \parallel f \parallel_\infty^2}{n} \quad \forall f \in B(\mathbb{S}_X) \label{eqn:identity:pibar}
	\end{align}
	\begin{proof}
		The first identity is obtained by substituting definitions for empirical measures as:
		\begin{align}
		 p_t^n &:= \frac{1}{n}\sum_{i=1}^n \delta(\bar{x}_t^{(i)}) = \frac{1}{n}\sum_{i=1}^n \delta(K_{t-1} x_{t-1}^{(i)} ) \\
		 \implies \ex{p_t | \mathcal{G}_{t-1}} &= \frac{1}{n}\sum_{i=1}^n  \ex{\delta(K_{t-1} x_{t-1}^{(i)} ) | \mathcal{G}_{t-1}} \\
		 &= \frac{1}{n}\sum_{i=1}^n  K_{t-1} \delta( x_{t-1}^{(i)} ) \\
		 &= K_{t-1} \frac{1}{n}\sum_{i=1}^n  \delta( x_{t-1}^{(i)} ) \\
		 &= K_{t-1} \pi_{t-1}^n\\
		\end{align}
		For the second identity, each particle $\bar{x}_t^{(i)}$ replaces itself  $\xi_t^{(i)}$ number of times, that is,  $\bar{x}_t^{(i)}$ is counted up  $\xi_t^{(i)}$ number of times in the re-sampled posterior $\pi_t^n$. Hence we can write the resampled posterior as:
		\begin{align}
		\pi_t^n  &\equiv \sum_{i=1}^{n} \mathbb{P}(\bar{x}_t^{(i)} \mathrm{chosen})	\cdot \delta(\bar{x}_t^{(i)}) \\
		&= \sum_{i=1}^{n} \left(\frac{\xi_t^{(i)}}{\sum_{k=1}^n {\xi_t^{(k)}}} \right)	\delta(\bar{x}_t^{(i)}) \\
		&= \sum_{i=1}^{n} \left(\frac{\xi_t^{(i)}}{n} \right)	\delta(\bar{x}_t^{(i)}) \\
		\end{align} The last line follows from the previously stated assumption that the number of particles are held constant after each resampling step. 
		
		To derive the last identity, we re-write terms of $n$ dimensional vectors whose elements represent individual particles:
		\begin{align}
		(\pi_t^n - \bar{\pi}_t^n)^2 &:= (W_t f_t)^T (W_t f_t) \\
		f_t& := f(\delta(\bar{x_t})), \quad \delta(\bar{x_t}) = [\delta(\bar{x_t}^{(1)}), \hdots, \delta(\bar{x_t}^{(n)})]^T \\		
		W_t& := \frac{\xi_t - nw_t}{n},  \quad \xi_t := [ \xi_t^{(1)}, \hdots, \xi_t^{(n)}], w_t := [w_t^{(1)}, \hdots, w_t^{(n)}]
		\end{align} Since $f$ is a bounded, Borel measurable function, we assume there exists $ f_\infty \geq f(\delta(\bar{x_t})) $ i.e. the limiting vector for all $t, n$. 
		\begin{align}
		\ex{(\pi_t^n - \bar{\pi}_t^n)^2} &:= \ex{(W_t f_t)^T (W_t f_t)} \\
		& = \frac{1}{n^2}\ex{f_t^T (\xi_t - nw_t)^T(\xi_t - nw_t) f_t } \\
		& \leq \frac{1}{n^2}\ex{f_\infty^T (\xi_t - nw_t)^T(\xi_t - nw_t) f_\infty } \\
		& = \frac{1}{n^2} f_\infty^T \ex{ (\xi_t - nw_t)^T(\xi_t - nw_t } f_\infty\\
		& = \frac{1}{n^2} f_\infty^T A_t^n f_\infty \\
		& = \frac{\parallel f\parallel_\infty^2}{n^2} \frac{f_\infty^T}{\parallel f\parallel_\infty} A_t^n \frac{f_\infty}{\parallel f\parallel_\infty} \\
		& = \frac{\parallel f\parallel_\infty^2}{n^2} q^T A_t^n q, \quad q = \frac{f_\infty}{\parallel f\parallel_\infty} \\
		& \leq \frac{\parallel f\parallel_\infty^2}{n^2} c_t n	
		= \frac{c_t \parallel f\parallel_\infty^2}{n} \\
		\implies \ex{(\pi_t^n - \bar{\pi}_t^n)^2}  & \leq \frac{c_t \parallel f\parallel_\infty^2}{n}
		\end{align}
	\end{proof}
\end{lemma}

\begin{lemma} [Bain \& Crisan, 2009]
	Assume that the transition kernel for $X$ is Feller, and the liklehihood functions are continuous. Then the sequence $p^n_t$ converges to $p_t$ and $\pi^n_t$ converges to $\pi_t$ almost surely, for all $t \geq 0$, if and only if:
	\begin{align}
		& \lim_{n\to \infty} \pi_0^n = \pi_0 \quad \mathbb{P}-\mathrm{a.s.} \\
		& \lim_{n\to \infty} d(p^n_t, K_{t-1}\pi^n_{t-1})  = 0 \quad \mathbb{P}-\mathrm{a.s.} \\
		& \lim_{n\to \infty} d(\pi^n_t, \bar{\pi}^n_{t})  = 0 \quad \mathbb{P}-\mathrm{a.s.}
	\end{align} where $d(\cdot, \cdot)$ is any metric that generates a weak topology on the space of finite measures, $\mathcal{M}$. 
\end{lemma}

\begin{theorem} [Bain \& Crisan, 2009] \label{bain:pfconvergence}
	Assume that for all $t$, there exists a constant $k_t$ such that $p_tg_t \geq k_t$ and the covariance matrix of a branching mechanism satisfies $q^t A_t^n q \leq n c_t$ . Then for a random observation vector $\pi_t^n \equiv \pi_t^{n, Y_{0:t}}$ and $p_t^n \equiv p_t^{n, Y_{0:t}}$ yield:
	\begin{align}
	\lim_{n\to \infty} \ex{|\pi_t^n f - \pi_t f|} &= 0 \\
	\lim_{n\to \infty} \ex{|p_t^n f - p_t f|} &= 0 
	\end{align}
	for all $f \in B(\mathbb{S}_X), t \geq 0$. 
	
	\begin{proof}
	Following the proof structure suggested in \cite{bain2009}, we use \cref{eqn:convergence:lemma:pibar}. First, we observe show convergence for the initial conditions. Since $\delta(x_0^{(i)}) \sim \pi_0$ and $\pi_0^n(1) = 1, \forall n$ , then the dominated convergence theorem  for measure valued random variables applies:
	\begin{align}
	\lim_{n \to \infty} \pi_0^n = \pi_0 \implies \lim_{n \to \infty} \ex{|\pi_0^n f - \pi_0f|} = 0, \quad \mathbb{P}-\mathrm{a.s.}.
	\end{align} This verifies \cref{eqn:conv:3}.
	For \cref{eqn:conv:4}, we use \cref{eqn:identity:dynamics}, $\ex{p_t f | \mathcal{G}_{t-1}} =  \pi_{t-1}^n (K_{t-1}f) \equiv \mu$
	\begin{align}
	\ex{(p^n_tf - K_{t-1} \pi^n_{t-1}f)^2 | \mathcal{G}_{t-1}} &:= \ex{(p^n_tf - \mu)^2 | \mathcal{G}_{t-1}} = \ex{(p^n_tf)^2} - \mu^2  \\
	& = \ex{(p^n_tf)^2} - (\pi_{t-1}^n (K_{t-1}f))^2 \\
	& = \frac{1}{n^2}\ex{(\sum_{i=1}^n f(\bar{x}_t^{(i)}))^2} - \frac{1}{n^2}(\sum_{i=1}^n K_{t-1}f(x_{t-1}^{(i)}))^2 \\
	& = \frac{1}{n^2}\sum_{i=1}^n \left( \ex{(f(\bar{x}_t^{(i)}))^2} - (K_{t-1}f(x_{t-1}^{(i)}))^2 \right) \\
	& = \frac{1}{n^2}\sum_{i=1}^n \left( K_{t-1} f^2(x_{t-1}^{(i)}) - (K_{t-1}f(x_{t-1}^{(i)}))^2 \right) \\
	& = \frac{1}{n}\pi_{t-1}\left( K_{t-1} f^2 - (K_{t-1}f)^2 \right) \\
	&\leq \frac{\parallel f \parallel_\infty}{n}
	\end{align} In the above, the sums are brought outside of expectation values due to independence of samples $\bar{x}_t^{(i)}$ and where $\pi^n_t f \leq \parallel f \parallel_\infty, \forall n$, as defined earlier. The result above implies the limit in  \cref{eqn:conv:4}. If  \cref{eqn:conv:4} holds, then  \cref{eqn:conv:5} is true by the proof given under \cref{eqn:convergence:lemma:pibar}. 
	\end{proof}
		
\end{theorem}

\begin{lemma} [Bain \& Crisan, 2009]
	If the offspring distributions are multinomial, then all properties of the branching mechanism are satisfied. 
		\begin{proof}
		Let $\xi_t^{(i)}$ be a multinomially distributed where the probability of choosing particle $\bar{x}_t^{(i)}$ is proportional to its weight  $w_t^{(i)}$
		\begin{align}
		\mathbb{P}(\xi_t^{(i)} = m^{(i)}) := \frac{n!}{\prod_{i=1}^{k} m^{(i)}!} \prod_{i=1}^{k}( w_t^{(i)})^{m^{(i)}}
		\end{align}
		Then by the properties of the multinomial distribution, we obtain expectation values of means and covariances matrix that satisfy the assumptions of the required branching mechanisms:
		\begin{align}
		\ex{\xi_t^{(i)} | \bar{\mathcal{G}}_t } &= n  w_t^{(i)} \\
		A_t^n & := \ex{(\xi_t - nw_t)^T(\xi_t - nw_t)} \\
		(A_t^n)_{i,j} &=\begin{cases}
		n w_t^{(i)} (1 - w_t^{(i)}), \quad  i =j \\
		- n w_t^{(i)} w_t^{(j)}, \quad  i \neq j 
		\end{cases}\\
		\xi_t &:= [ \xi_t^{(1)}, \hdots, \xi_t^{(n)}]\\
		w_t &:= [w_t^{(1)}, \hdots, w_t^{(n)}] \\
		\implies q^T A_t^n q_t & := \sum_{i=1}^n \sum_{j=1}^n q_i q_j (A_t^n)_{i,j} \\
		&= \sum_{i=1}^n q_i q_i n w_t^{(i)} (1 - w_t^{(i)}) - \sum_{i\neq j}^n \sum_{j=1}^n n q_i q_j  w_t^{(i)} w_t^{(j)} \\
		&= \sum_{i=1}^n q_i q_i n w_t^{(i)} - \sum_{i= 1}^n \sum_{j=1}^n n q_i q_j  w_t^{(i)} w_t^{(j)} \\
		&= n \sum_{i=1}^n (q_i)^2 w_t^{(i)} - n (\sum_{i= 1}^n  q_i w_t^{(i)})^2 \\
		&\leq  n \sum_{i=1}^n (q_i)^2 w_t^{(i)} \\
		&\leq  n \sum_{i=1}^n w_t^{(i)}, \quad |q_i| \leq 1 \forall i \\
		&=  n \\
		\implies c_t &= 1 \quad \forall t
		\end{align} 
		\end{proof}
\end{lemma}


\subsection{qslam}

qslam is an inference procedure designed for a 2D array of qubits coupled to a common classical, time-invariant dephasing field that is continuously varying in space. Below we define the observations, state variables and the filtering problem that collectively defines the qslam inference procedure. 

\begin{defn}
	Let a system consist of $d$ qubits and define a total budget of $T$ measurements taken at $t=1, 2, \hdots, T$. Let the locations of the qubits be labeled by $\{1, 2, \hdots d\}$. A measurement $Y_t^{(j_t)} \in \{0,1\}$ is a random variable obtained by measuring a single qubit at the location $j_t \in \{1, 2, \hdots d\}$ at time $t$. 
\end{defn}

\begin{defn} \label{qslam:def:Fstatevariable}
	Define the state vector $F_t \in \mathbb{S}_F := [0, \pi]^d$ the set of random variables over each of the qubit locations, taking in values between $[0, \pi]$, such that $F_t^{(j_t)}$ is the $j_t$ element of $F_t$, and $F_t^{(j_t)}$defines value of the so-called Born phase  for the qubit at location $j_t$. The set of phases for all qubits in the system is the random vector $F_t$ and is referred to as the `true map' or equivalently, as the set of `map values'.
\end{defn}

\begin{defn} The measure for $F_0$  $(\mathbb{S}_{F_0}:= [0, \pi]^d, \mathcal{S}_{F_0}:= \ofieldgen{\mathbb{S}_{F_0}})$ is uniformly distributed over outcomes in $\mathbb{S}_{F_0}$. 
\end{defn}

\begin{proposition}
	The measurement model is a single qubit measurement at location $j_t$ and time $t$:
	\begin{align}
	Y_t^{(j_t)} := \mathcal{Q}(\frac{1}{2} \cos(F_t^{(j_t)}) + v_t + \frac{1}{2}) \label{qslam:measurementmodel}
	\end{align}
	Here, $\mathcal{Q}$ represents a Bernoulli trial parameterised by a probability that depends on the Born phase and $v_t$ represents a truncated Gaussian error model with zero mean and $\Sigma_R$ variance.	
	The likelihood function for this model is:
	\begin{align}
	 g_1(\cdot, Y_t^{(j_t)}) & :=  \frac{\rho_0}{2} + \frac{\rho_0  \cos(F_t^{(j_t)}) }{2} \left( \delta(Y_t^{(j_t)} - 1) - \delta(Y_t^{(j_t)}) \right) \label{qslam:likelihood:g1:func} \\
	\rho_0 &: =  \erf(\frac{2b}{\sqrt{2\Sigma_R}}) + \frac{\sqrt{2\Sigma_R}}{2b} \frac{e^{-(\frac{2b}{\sqrt{2\Sigma_R}})^2}}{\sqrt{\pi}}  - \frac{1}{2b}\frac{\sqrt{2\Sigma_R}}{\sqrt{\pi}}, b := 1/2 \label{qslam:likelihood:g1:rho0} 
	% F_t^{(j_t)} & \gets h_1(\lambda_1, \cdot)
	\end{align}
	\begin{proof}
	{\color{red} Refer: \cite{riddhinotes}. (Do a concise version of the previous CRLB notes here. $g_1(\cdot, Y_t^{(j_t)}) $ is a placeholder for dependence of $ g_1$  on $\lambda_1$ due to data association procedure for $F_t^{(j_t)}$) }
	\end{proof}
\end{proposition}	

With the above definitions, one can conduct a basic form of inference. However, all definitions are with respect to a single qubit measurement and single qubit likelihoods where qubits are independent from each other. 

We now construct a mechanism to share state information between qubits within a local neighbourhood. The cost of this mechanism will be to correlate state variables with measurement errors when the number of physical measurements are small. However, we design this mechanism that in the limit of large physical data collection, measurement errors gradually become less correlated until state estimation is unbiased.\\
\\
To construct this mechanism, we use the concept of `blurring' state information from a point value at $j_t$ into a small neighbourhood, $Q_t$, around $j_t$. Both the size of the neighbourhood and the type of sharing mechanism is parameterised by  a random variable, $R_t^{(j_t)}$, called a length-scale at $j_t$. Given a map $F_t$, we associate a likelihood function for the length-scale at $j_t$, $R_t^{(j_t)}$, that scores the most appropriate length-scale (hence neighborhood size) for sharing information between qubits in the next iteration of the state estimation procedure.  Posterior state information at $j_t$ is subsequently shared across other qubit locations via so-called quasi-measurements. These terms are defined below.

\begin{defn} For some $R_{min} \in \mathbb{R} > 0$, define the state vector $R_t \in  \mathbb{S}_R := [R_{min}, \infty)^d$ the set of random variables associated with $d$ qubit locations, taking in values between $[R_{min}, \infty)$, such that $R_t^{(j_t)}$ is the $j_t$ element of $R_t$, and $R_t^{(j_t)}$ is the so-called `length-scale' for the qubit at location $j_t$. The length-scale parameterises a Gaussian function with amplitude $F_t^{(j_t)}$  that spreads the point-value of the phase $F_t^{(j_t)}$, at $j_t$, into a small neighbourhood. Let $\nu_{(j_t,q)}$ be the separation distance between the qubit at $j_t$ and a point $q$ in a neighbourhood around $j_t$. Then the smeared phase value is given by:
	\begin{align}
	\bar{F}(\nu_{(j_t,q)}) &: = F_t^{(j_t)} \exp\left( \frac{- \nu_{(j_t,q)}^2}{(R_t^{(j_t)})^2}\right) \label{qslam:defn:bar_F}\\
	\end{align}
The point value of the phase  is regained in the limit $R_t^{(j_t)} \to 0$, and the smallest spatial resolution sets the value of $R_{min}$.  \\
\\
Let $q_t$ denote the location labels for all qubits excluding the measured qubit, $ q_t \in \{1, 2, \hdots d \} \setminus \{j_t\} $. Then the neighbourhood, $Q_t$ of the measured qubit at $j_t$ with length-scale $R_t^{(j_t)}$ is the set:
\begin{align}
Q_t : = \{ q_t | \nu_{(j_t, q_t)} \leq k_0 R_t^{(j_t)}, \forall q_t \in \{1, 2, \hdots d \} \setminus \{j_t\} \}, \quad k_0 \in [1, \infty). \label{qslam:defn:Q_t} 
\end{align} That is, neighbours are the set of qubits whose separations distances fall within a radius of $k_0 R_t^{(j_t)}$ about the location $j_t$. Here, $k_0$ is an arbitrary constant that truncates the neighbourhood when smeared phase values at the boundary of the neighborhood are dissimilar to those at the center. Currently $k_0=1$.
\end{defn} 
The next definition specifies the likelihood for the length-scale $R_t^{(j)}$ given $F_t$, and the likelihood calculation is based on the idea of comparing state information between qubits in a neighbourhood. 
\begin{defn}
	Given a constant $\lambda_2 \in [0,1]$, a non-negative natural number $\tau_{q_t}$, and all neighbors in a neighbourhood $Q_t$ around $j_t$, the likelihood for the length-scale at $j_t$ compares the estimate $\mathcal{X}_{q_t} $ to the best available phase information, $F_t^{(q_t)}$, on each neighbour $q_t \in Q_t$:
	\begin{align}
		F_t^{(q_t)} &= \mathcal{X}_{q_t} + w_t, \quad \forall q_t \in Q_t  \label{qslam:defn:msmtmodel:Rt}\\
		\mathcal{X}_{q_t} &:= (1 - \lambda_2^{\tau_{q_t}})F_t^{(q_t)} + \lambda_2^{\tau_{q_t}} \bar{F}(\nu_{(j_t,q_t)}) \label{qslam:defn:msmtmodel:Rt:Xqt} \\
		w_t & \sim \mathcal{N}(\mu_F, \Sigma_F) \\
		g_2(\lambda_2, Q_t) & := \prod_{q_t \in Q_t} \frac{1}{k_1\sqrt{2\pi \Sigma_F}} \exp \left( -\frac{( F_t^{(q_t)} - \mathcal{X}_{q_t}(\lambda_2) - \mu_F )^2}{2 \Sigma_F }\right) \label{qslam:defn:likelihood:Rt} \\
		k_1&:= \frac{1}{2}\left(\erf(\frac{\pi + \mu_F}{\sqrt{2\Sigma_F}}) + \erf(\frac{\pi - \mu_F}{\sqrt{2\Sigma_F}})\right)
	\end{align} The quantity $\mathcal{X}_{q_t}$ is based on a weighted average of both current map estimate on the neighbouring qubit and state estimates of physically measured qubit at $j_t$, mediated by a factor $\lambda_2^{\tau_{q_t}}$. The noise parameters $ \mu_F, \Sigma_F$ represent the true error in approximating a continuously varying spatial field with overlapping Gaussian functions. We assume that the true error is Gaussian distributed and error values lie in the finite interval $[-\pi, \pi]$, giving rise to the constant $k_1$. \\
	\\
	Along with $ \mu_F, \Sigma_F$, the non-negative $\lambda_2$ is assumed known or learned as a hyper-parameter for the filtering problem, and the constant $ \tau_{q_t} \leq T$  is the tally of the total number of times $q_t$ has been physically measured, as defined in \cref{qslam:dataassoc:h1}, whereas $\lambda_2$ is a hyper-parameter of the qslam model. 
\end{defn}

\begin{defn} The measure for $R_0$  $(\mathbb{S}_{R_0}:= [R_{min}, \infty)^d, \mathcal{S}_{R_0}:= \ofieldgen{\mathbb{S}_{R_0}})$ is uniformly distributed over outcomes in $\mathbb{S}_{R_0}$.
\end{defn} 
Given the prior distributions, a Feller transition kernel, and likelihood functions for both state variables, we assume that some posterior distribution $\pi_t^n$ is obtained  at time $t$ given a measurement at location $j_t$. This posterior represents the best information we have about the maps and the relevant lengthscales for each qubit locally. Based on the posterior  $F_t$ and $R_t^{(j)}$, we use the concept of quasi-measurements to share posterior state information across qubit locations in the qslam model.
 \begin{defn} \label{qslam:defn:quasimsmts}
 	Given a posterior state estimate $F_t$ and $R_t^{(j)}$ at time $t$, a physical measurement at $j_t$ is said to \textit{induce} quasi-measurements in the posterior neighbourhood $Q_t$, where $Q_t \text{ (posterior)} \equiv Q_{t+1} \text{(prior)}$. That is, the random variable $\hat{Y}_{t+1}^{(q_{t+1})} \in \{0,1\}$ is generated at the location $q_{t+1} \in \{1, 2, \hdots d\} \setminus \{j_t\}$ at time $t+1$ using the model:
 	\begin{align}
 	\hat{Y}_{t+1}^{(q_{t+1})}  & := \mathcal{Q}(\frac{1}{2} \cos(\mathcal{X}_{q_t}) + \frac{1}{2}) \label{qslam:defn:quasimsmts:1}
 	\end{align} The quasi-measurement is based on a weighted average of both posterior map estimate on the neighbouring qubit and posterior state information shared by physically measured qubit at $j_t$, mediated by a factor $\lambda_2^{\tau_{q_t}}$. Note that $\mathcal{X}_{q_t}$ is to be interpreted as the posterior \cref{qslam:defn:msmtmodel:Rt:Xqt}, where $ q_{t+1} \in Q_{t+1}$ (above) equals the $Q_t$ set by posterior state estimate $R_t^{(j)}$ and the posterior $F_t$ is used for all calculations. 
 \end{defn}

We are now in a position to state the non-linear filtering problem for qslam in terms of a state variable $X$ and an observation vector $Z$. 

\begin{defn} \label{qslam:filteringprob}
Let $X = \{X_t, t = 1, 2, \hdots \}$ be a stochastic process defined on the composite probability space $(\samplespace{X}, \family{X}, \measure{{}}{\cdot})$. 
Define the state vector at $t$  by $X_t = (F_t, R_t) \in \mathbb{S}_{X} := \mathbb{S}_{F} \times \mathbb{S}_{R}$. Let the filteration generated by the process $X$ as $\mathcal{F}_{t} := \sigma(\{X_s, s\in[0, t]\})$. \\
\\
By definition, the family of random variables $\{X_s, s\in[0, t]\}$ is $\mathcal{F}_{t}$-measurable for each $t$. Further, the Borel \ofield{}s generated  are of increasing size  $\mathcal{F}_{t-1} \subset \mathcal{F}_{t} \subseteq \mathcal{F}_{X}$. Denote  $X_{0:t} := (X_0, \hdots, X_t)$ as the set of state variables until $t$. Additionally, we specify $X$ is Markov with a Feller transition kernel.\\
\\
Let $Z_t = (Y_t^{(j_t)}, \{\hat{Y}_t^{(q_t)}\}_{q_t \in Q_t}) \in $ be the observational vector at time $t$ due to a single physical measurement at $j_t$ and a set of quasi-measurements $\{\hat{Y}_t^{(q_t)}\}_{q_t \in Q_t}$ in a neighbourhood $Q_t$ about $j_t$. Define the observational vector $Z := \{ Z_t, t = 1, 2, \hdots \}$ and denote  $Z_{0:t} := (Z_0, \hdots, Z_t)$ as the measurement record until $t$.\\
\\
Then, the filtering problem is to compute a random measure $\pi_t$ that is the conditional probability of  $X$ given the \ofield{} generated by the observation process $Z_{0:T}$:
\begin{align}
\pi_t &:= \measure{{}}{X_t \in A | \ofieldgen{Z_{0:T}}}, \quad \forall A \in \mathcal{S}_X \\
\pi_t f &= \ex{f(X_t) |  \ofieldgen{Z_{0:T}}} \quad \forall f \in B(\mathbb{S}_X), A \in \mathcal{S}_X \\
\pi_0 & \sim \mathcal{U}(\mathbb{S}_X)
\end{align}

For some constant $\lambda_2 \in [0,1]$ and a non-negative natural number $ \tau_{q_t} \leq T$,  total likelihood function for each $Z_t=z_t$ is given by:
\begin{align}
g_t^{z_t} &: = g_1(\cdot, Y_t^{(j_t)}) g_2(\lambda_2, Q_t) \label{qslam:defn:globallikelihood}\\ 
& = \left(\frac{\rho_0}{2} + \frac{\rho_0  \cos(F_t^{(j_t)}) }{2} \left( \delta(Y_t^{(j_t)} - 1) - \delta(Y_t^{(j_t)}) \right) \right) \prod_{q_t \in Q_t} \frac{1}{k_1\sqrt{2\pi \Sigma_F}} \exp \left( -\frac{( F_t^{(q_t)} - \mathcal{X}_{q_t} - \mu_F )^2}{2 \Sigma_F }\right) \\
\mathcal{X}_{q_t} &:= (1 - \lambda_2^{\tau_{q_t}})F_t^{(q_t)} + \lambda_2^{\tau_{q_t}} \bar{F}(\nu_{(j_t,q)}) \\
k_1&:= \frac{1}{2}\left(\erf(\frac{\pi + \mu_F}{\sqrt{2\Sigma_F}}) + \erf(\frac{\pi - \mu_F}{\sqrt{2\Sigma_F}})\right) \\
\rho_0 &: =  \erf(\frac{2b}{\sqrt{2\Sigma_R}}) + \frac{\sqrt{2\Sigma_R}}{2b} \frac{e^{-(\frac{2b}{\sqrt{2\Sigma_R}})^2}}{\sqrt{\pi}}  - \frac{1}{2b}\frac{\sqrt{2\Sigma_R}}{\sqrt{\pi}}, b := 1/2
\end{align}
The noise parameters that govern the level of uncertainty in the system are: $\Sigma_R, \mu_F, \Sigma_F$, where $\Sigma_R$ captures variance of zero mean measurement noise from a truncated Gaussian error model, and $ \mu_F, \Sigma_F$ represent the true error in approximating a continuously varying fields with overlapping Gaussian neighborhoods. The non-negative $\lambda_2 \in [0,1]$ and the constant $ \tau_{q_t} \leq T$  are known, and collectively, these two parameters regulate the extent to which quasi-measurements are ignored by the inference procedure. 
\end{defn} 

The filtering problem, so defined, is challenging as the space of maps and lengthscales is very large. Instead, we use an iterative maximum likelihood approach analogous to the method employed in \cite{thrun2001probabilistic}. Suppose one has available two data association mechanisms, $h_1$ and $h_2$, such that one can update the state variables directly using data incoming at $t$. Then the iterative maximum likelihood approach assumes that the posterior state at $t-1$ (prior at $t$) is known, and the functions $h_1$ and $h_2$ are used to update the state variables $F_t$ and $R_t$ iteratively, such that the global likelihood $g_t^{z_t}$ is maximised.\\
\\
To implement an iterative maximum likelihood procedure in a particle filter, we define a particle set for qslam as follows. Its usefulness will be evident in \cref{prop:qslam:branching}. 

\begin{defn}
Assume $t > 0$ and the particle filter has $n_\alpha$ number of particles at the start and end of a two-step iteration process i.e. total number of resampled particles are constant for all $t$.\\
\\
Let the set of particles at the beginning and end of each time-step $t$ be called $\alpha$-type particles, indexed by the set of numbers $\{1, 2, \hdots, n_\alpha\}$. For each $\alpha$-particle, we associate a set of $\beta^{(\alpha)}$-particles labeled from $\{1, 2, \hdots, n_\beta \}$, the so-called `$\beta$-layer' for an $\alpha$-particle. Define the single $\beta^{(\alpha)}$-particle as a particle with state $X_t \setminus \{R_t^{(j_t)}\} $ inherited from its $\alpha$-parent; and additionally, a single uniformly distributed sample for $R_t^{(j_t)}$ from the length-scale prior distribution. \\
\\
The set of all particles can be summarised by a probability decision tree with $n_\alpha n_\beta$ leaves, where each $\alpha$ particle is the child of the root node and the height of the tree is two. Let an $\alpha$-particle be weighted according to $ g_1(\cdot, Y_t^{(j_t)})$ and normalised over the set of $\alpha$-particles. Let a $\beta^{(\alpha)}$-particle be weighted by $g_2(\lambda_2, Q_t)$, and normalised over the $\beta$-layer for one  $\alpha$-particle. Then the total likelihood $g_t^{z_t}$ over tfhe entire particle set is given by the product of the $\alpha$ and $\beta$ particle weights. %At the end of each time step, $\beta^{(\alpha)}$ layer is marginalised out, such that the total particle number is  $n_\alpha$. 
\end{defn}
The $\beta^{(\alpha)}$ layer represents the reverse marginalisation over the distribution of lengthscales at $R_t^{(j_t)}$ given $F_t$.  The two tiered-particle approach yields the following branching mechanism for qslam.
\begin{proposition} \label{prop:qslam:branching}
	
	Given time, $t$, and an incoming data stream, $Z_t$:
	\begin{enumerate}
	\item Assume $\bar{X}_{t} = K_{t-1}X_{t-1}$ is known. \label{prop:qslam:branching:1}
		\begin{enumerate}
			 \item Update $F_t^{(j_t)}$ for each $\alpha$-particle using $h_1$. 
			 \item Weight each $\alpha$-particle according to $ g_1(\cdot, Y_t^{(j_t)})$.
		\end{enumerate}
	\item Assume $F_t$ is known. \label{prop:qslam:branching:2}
		\begin{enumerate}
			\item For each $\alpha$-particle, generate $n_\beta$ number of particles of a second type,  called $\beta^{(\alpha)}$-particles.
			\item Weight each $\beta^{(\alpha)}$-particle according $g_2(\lambda_2, Q_t)$.
	\end{enumerate}
	\item Maximise global likelihood $ g_t^{z_t}$:  obtain $n_\alpha$ particles by resampling the full set of $n_\alpha n_\beta$ particles according to the product of their weights \label{prop:qslam:branching:3}
	\item Update $R_t^{(j_t)}$ for each $\alpha$-particle by applying $h_2$ to its $\beta^{(\alpha)}$ layer. \label{prop:qslam:branching:4}
	\item Marginalise over $\beta^{(\alpha)}$ layer yielding $n_\alpha$ number of $\alpha$-particles with uniform weights.  \label{prop:qslam:branching:5}
	\end{enumerate} 
\end{proposition}
The branching mechanism of \cref{prop:qslam:branching} can be explained in words as follows. In step \ref{prop:qslam:branching:1}, the function $h_1$ updates $F_t^{(j)}$ deterministically using noisy physical measurements via Born's rule. Noise filtering occurs when $\alpha$-particles are scored via the likelihood function $g_1(\cdot, Y_t^{(j_t)})$.  In step \ref{prop:qslam:branching:2}, we reverse marginalise the distribution over length-scales given $F_t$. We maximise the likelihood over the joint-distribution of both lengthscales and maps in step \ref{prop:qslam:branching:3}. Given a posterior set of resampled particles, we update our knowledge about $R_t^{(j_t)}$ and marginalise out lengthscales in steps \ref{prop:qslam:branching:4}-\ref{prop:qslam:branching:5}. \\
\\
To fully specify the branching mechanism, we need to define the data association mechanisms $h_1$ and $h_2$ over a Markov state space. 
\begin{defn} \label{qslam:dataassoc:h1}
	For some non-negative constant $\lambda_1$, let $h_1(\lambda_1, Z_t)$ be deterministic data association mechanism which updates the state variable $F_t^{(j)}$  given $X_{t-1}$ as:
	\begin{align}
	F_t^{(j)} &:= \begin{cases}
	F_{t-1}^{(j)}, \quad \tau_t^{(j)}, \varphi_t^{(j)} = 0 \\
	h_1(\lambda_1, Z_t), \quad \mathrm{otherwise}   \\
	\end{cases} \\
	h_1(\lambda_1, Z_t)& := \cos^{-1} (2P_t^{(j)}(\lambda_1, Z_t) - 1) \\
	P_t^{(j)}(\lambda_1, Z_t) &:= \begin{cases}
	\left( 1- \frac{\lambda_1^{\tau_t^{(j)}}}{2}\right)\kappa_{t}^{(j)} + \left(\frac{\lambda_1^{\tau_t^{(j)}}}{2}\right)\gamma_{t}^{(j)}, \quad \tau_t^{(j)}, \varphi_t^{(j)} \neq 0 \\
	\kappa_{t}^{(j)}, \quad \tau_t^{(j)}\neq 0, \varphi_t^{(j)} = 0 \\
	\gamma_{t}^{(j)}, \quad \tau_t^{(j)} = 0, \varphi_t^{(j)} \neq 0 \\
	\end{cases}\\
	\kappa_{t}^{(j)} &:= \frac{\tau_{t-1}^{(j)}}{\tau_{t}^{(j)}}  \kappa_{t-1}^{(j)} + \frac{1}{\tau_t^{(j)}} Y_t^{(j_t)}I_{(j_t = j)}, \quad \tau_t^{(j)} \neq 0, 	\kappa_{0}^{(j)} =0 \\
	\gamma_{t}^{(j)} &:= \frac{\varphi_{t-1}^{(j)} }{\varphi_{t}^{(j)}} \gamma_{t-1}^{(j)} + \frac{1}{\varphi_t^{(j)}} \hat{Y}_t^{(q_t)}I_{(q_t= j, q_t \in Q_t)} , \quad \varphi_t^{(j)} \neq 0, \gamma_{0}^{(j)} =0\\
	\tau_t^{(j)} &:= \tau_{t-1}^{(j)} + I_{(j_t = j)}, \quad \tau_0^{(j)} =0 \\
	\varphi_t^{(j)} &:= \varphi_{t-1}^{(j)} + I_{(q_t= j, q_t \in Q_t)}, \quad \varphi_0^{(j)} =0  \\
	I_{X} &:= \begin{cases}
	1, \quad X \\
	0, \quad \neg X 
	\end{cases} \\
	\lambda_1 &\in [0,1] 
	\end{align}
	We see that $P_t^{(j)}$ is just an empirical Born probability estimate obtained by averaging the binary measurement data obtained at a single qubit. This data consists of averaging over $\tau_t^{(j)}$ physical measurements at qubit $j$,  and $\varphi_t^{(j)}$ quasi-measurements induced by measuring the neighboring qubits of $j$. The role of quasi-measurements in data association is reduced as the number of physical measurements, $\tau_t^{(j)}$, increases, at a rate governed by the choice of $\lambda_1$.
	
	In notation, we replace $ g_1(\lambda_1, Y_t^{(j_t)}) \gets  g_1(\cdot, Y_t^{(j_t)})$ to make the dependence of the noise density function on the data association hyper-parameter $\lambda_1$ explicit. \\
\end{defn}

\begin{defn}
	 Let $h_2$ be deterministic data association mechanism which locally updates the state variable $R_t^{(j_t)}$ as the expectation over resampled $\beta$-particles given the state at $F_t$:
	 \begin{align}
	 R_t^{(j_t)} := h_2(F_t) = \ex{\{R_t^{(j_t), n}\}_{n=1}^{n_\beta} | F_t}
	 \end{align} The dependence on $F_t$ is implicit, as $\beta$-particles are weighted via the $g_2(\lambda_2, Q_t)$ likelihood function for which it is assumed $F_t$ is known.
\end{defn}

\begin{proposition} \label{qslam:convergence}
	For Markov $X$, with identity dynamics and a constant particle number $n_\alpha$, qslam converges with $c_t=1$. 
	
	\begin{proof} The proof proceeds by verifying that the conditions of \cref{bain:pfconvergence} are met. Since the transition kernel is Feller, and the prior reflects our level of apriori knowledge of the system, we only need only to verify that the re-sampling scheme in \cref{prop:qslam:branching} satisfies the conditions in \cref{prop:banchingproperties}. That the resampling scheme in qslam is multinomial  is a direct application of the multi-nomial theorem.
	
	To see this, consider the re-sampling mechanism at time $t$. Let $N$ be the total number of samples from a multi-nomial distribution. Let the set $\{ j= 1, 2, \hdots, n_\alpha n_\beta\}$ denote the full set of particles for both $\alpha$ and $\beta$ layers, where the probability of success $w_t^{(j)}$ is given by $g_t^{z_t}$ for the $j$-th particle. 
	
	%Then the multinomial distribution is:
	%\begin{align}
	%\mathbb{P}(\xi_t^{(j)} = m^{(j)}) := \frac{N!}{\prod_{j=1}^{n_\alpha n_\beta} m^{(j)}!} \prod_{j=1}^{n_\alpha n_\beta}( w_t^{(j)})^{m^{(j)}}
	%\end{align}
	
	Let the set of labels $\{ j= 1, 2, \hdots, n_\alpha n_\beta\}$ be partitioned into non-empty set of $\{A_i, i = 1, 2, \hdots,\kappa\}$ categories, where $\kappa < n_\alpha n_\beta$. Then the total number of particles is conserved over this re-grouping:
	\begin{align}
	N &= \sum_{j = 1}^{n_\alpha n_\beta}  m^{(j)} = \sum_{i = 1}^{\kappa}  z^{(i)} =\sum_{i = 1}^{\kappa} \sum_{j \in A_i}  m^{(j)} \\
	 z^{(i)} &:= \sum_{j \in A_i}  m^{(j)} 
	\end{align} Meanwhile, since $ A_i$ represents union of original categories, the success probability, $	\bar{w}_t^{(i)}$, of seeing $z^{(i)}$ counts in the $i$-th regrouped category is the sum over the probabilities of the original categories, $w_t^{(j)}$, for all $ j \in A_i$ i.e.
	\begin{align}
	\bar{w}_t^{(i)} = \sum_{j \in A_i} w_t^{(j)}
	\end{align}
	Then for $N$ constant, and by the multinomial-theorem, the random variables $Z_t^{(i)} = z^{(i)}$, where $Z_t^{(i)} = \sum_{j \in A_i}\xi_t^{(j)}$ are multinomially distributed with success probabilities $\bar{w}_t^{(i)}$. Setting $N = n_\alpha$ for all re-sampling steps means that the branching mechanism in qslam remains a multinomial distribution. Hence,  \cref{prop:banchingproperties} is satisfied with $c_t=1$.
	\end{proof}
		
\end{proposition}
 \cref{qslam:convergence} shows that marginalisation of $\beta$ particles means that each $\alpha$ particle is still being sampled according to its $\alpha$ weight, as if the $\beta$ layer didn't exist. Meanwhile, the update rule for $R_t^{(j_t)}$ via $h_2$ enables us to gain neighborhood information from the $\beta$-layer before marginalisation and enables sharing of information across qubits.\\
 \\

\end{widetext}




