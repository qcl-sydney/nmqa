{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import clfanalysis\n",
    "from clfanalysis.preamble import *\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "def cm2inch(cm):\n",
    "    return cm / 2.54\n",
    "\n",
    "startscript = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each notebook tests a single classifer type on a dataset.\n",
    "\n",
    "The classifier options are set by `clf_flag`:\n",
    "\n",
    "    'lr': Logistic Regression Classifier\n",
    "    'mpl': Multi-Layer Perceptron Classifier\n",
    "    'rf' : Random Forest Classifier\n",
    "\n",
    "The dataset options are set by `data_flag`:\n",
    "\n",
    "    '0' : CIFAR-10 Data\n",
    "    '1' : Fashion-MINST Data\n",
    "\n",
    "All other global parameters are set by `clfanalysis.globalparams`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_flag = 'mlp' \n",
    "data_flag = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clfanalysis.globalparams import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load + Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clfanalysis.preprocess import rescale, greyscale\n",
    "\n",
    "# load data:\n",
    "dataset = np.load(loadpath+datafiles[data_flag]+'.npz')\n",
    "Xtr = dataset['Xtr']\n",
    "Str = dataset['Str']\n",
    "Xts = dataset['Xts']\n",
    "Yts = dataset['Yts']\n",
    "\n",
    "\n",
    "# for MINST\n",
    "if data_flag == 1: \n",
    "    Xtr = rescale(Xtr)\n",
    "    Xts = rescale(Xts)\n",
    "\n",
    "# for CIFAR\n",
    "if data_flag == 0: \n",
    "\n",
    "    Xtr = np.asarray([greyscale(np.transpose(Xtr[sample, :].reshape(3, 32, 32), (1, 2, 0))) for sample in range(10000)])\n",
    "    Xts = np.asarray([greyscale(np.transpose(Xts[sample, :].reshape(3, 32, 32), (1, 2, 0))) for sample in range(2000)])\n",
    "    Xtr = rescale(Xtr.reshape(10000, 32*32))\n",
    "    Xts = rescale(Xts.reshape(2000, 32*32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processtime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 0\n",
      "Trial: 1\n",
      "Trial: 2\n",
      "Trial: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 5\n",
      "Trial: 6\n",
      "Trial: 7\n",
      "Trial: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/riddhisw/anaconda2/envs/QISKitenv/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (150) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from clfanalysis.trainclf import computeAccuracy, train_classifier\n",
    "\n",
    "results, class_prob_list, best_model_list = train_classifier(clfdict[clf_flag]['obj'], \n",
    "                                                             clfdict[clf_flag]['prm'], \n",
    "                                                             Xtr, \n",
    "                                                             Str, \n",
    "                                                             N_ITER, \n",
    "                                                             n_repeats, \n",
    "                                                             cv=cv, scoring='accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintime = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Testing with Importance Re-Weighting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clfanalysis.noisecorrections import estimate_Beta, estimate_flip_rates, clean_weights\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "estimatortype = ['tf', 'estf']\n",
    "\n",
    "if clf_flag == 'mlp':\n",
    "    estimatortype = [None]\n",
    "\n",
    "for idx_type in estimatortype + ['bare']:\n",
    "    if idx_type is not None:\n",
    "        vars()['acc_'+idx_type] = []\n",
    "\n",
    "rho_plus_list = []\n",
    "rho_minus_list = []\n",
    "cmatrix_list = []\n",
    "pi_list = []\n",
    "\n",
    "for pickrept in range(n_repeats):\n",
    "    \n",
    "    # Pick best model from each RandomisedCV trial with 5 Fold CV.\n",
    "    class_prob = class_prob_list[pickrept]\n",
    "    bestmodel = best_model_list[pickrept]\n",
    "    params = results[pickrept][\"params\"][bestmodel]\n",
    "    \n",
    "    # Estimate Noise Rates from class probabilities of the model acting on training data\n",
    "    alpha, beta, pi, rho_plus, rho_minus = estimate_flip_rates(class_prob[:, 1], Str.flatten())\n",
    "    rho_plus_list.append(rho_plus)\n",
    "    rho_minus_list.append(rho_minus)\n",
    "    pi_list.append(pi)\n",
    "    \n",
    "    \n",
    "    # Calculate weights using true and estimated noise rates\n",
    "    for idx_type in estimatortype:\n",
    "        \n",
    "        if idx_type is not None:\n",
    "        \n",
    "            if idx_type == 'estf':\n",
    "                vars()['weights_'+idx_type] = estimate_Beta(Str, class_prob, rho_minus, rho_plus)\n",
    "            \n",
    "            elif idx_type == 'tf':\n",
    "                vars()['weights_'+idx_type] = estimate_Beta(Str, class_prob, rho_0, rho_1)\n",
    "            \n",
    "            vars()['weights_'+idx_type] =  clean_weights(vars()['weights_'+idx_type])\n",
    "        \n",
    "    pick_data = np.random.randint(low=0, high=10000, size=8000)\n",
    "    \n",
    "    # Run new classifiers with best model parameters and importance re-weighting\n",
    "    for idx_type in estimatortype + ['bare']:\n",
    "        \n",
    "        if idx_type is not None:\n",
    "            \n",
    "            vars()['clf_'+idx_type] = clfdict[clf_flag]['func'](**params)\n",
    "            \n",
    "            X = Xtr[pick_data]\n",
    "            S = Str.flatten()[pick_data]\n",
    "            W = None\n",
    "            \n",
    "            if idx_type != 'bare':\n",
    "                W = vars()['weights_'+idx_type].flatten()[pick_data]\n",
    "\n",
    "            # Fit models\n",
    "            \n",
    "            if clf_flag != 'mlp':\n",
    "                vars()['clf_'+idx_type].fit(X, S, sample_weight=W)\n",
    "            elif clf_flag == 'mlp':\n",
    "                vars()['clf_'+idx_type].fit(X, S)\n",
    "\n",
    "            # Predict on Test Data\n",
    "            vars()['predY_'+idx_type] = vars()['clf_'+idx_type].predict(Xts)\n",
    "\n",
    "            # Store accuracy + confusion matrix\n",
    "            vars()['acc_'+idx_type].append(computeAccuracy(Yts, vars()['predY_'+idx_type]))\n",
    "            \n",
    "            if idx_type == 'bare':\n",
    "                matrixC = confusion_matrix(Yts, vars()['predY_'+idx_type])\n",
    "                cmatrix_list.append(matrixC.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx Total time\n",
      "7981.621993 seconds\n",
      "\n",
      "Approx Preprocessing time\n",
      "1.467915 seconds\n",
      "Approx Training time\n",
      "7814.828568 seconds\n",
      "Approx Testing time\n",
      "165.325511 seconds\n"
     ]
    }
   ],
   "source": [
    "endscript = time.time()\n",
    "\n",
    "print(\"Approx Total time\")\n",
    "print(\"%f seconds\" %(endscript - startscript))\n",
    "print()\n",
    "print(\"Approx Preprocessing time\")\n",
    "print(\"%f seconds\" %(processtime - startscript))\n",
    "print(\"Approx Training time\")\n",
    "print(\"%f seconds\" %(traintime - processtime))\n",
    "print(\"Approx Testing time\")\n",
    "print(\"%f seconds\" %(endscript - traintime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show accuracy scores for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bare:  0.68065\n"
     ]
    }
   ],
   "source": [
    "for idx_type in estimatortype + ['bare']:\n",
    "    \n",
    "    if idx_type is not None:\n",
    "        \n",
    "        print(idx_type + ': ', np.mean(vars()['acc_'+idx_type]))             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show 'best model' configurations for each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 200, 'learning_rate_init': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100), 'activation': 'logistic'}\n",
      "0.629\n",
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 200, 'learning_rate_init': 0.0001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 100, 100), 'activation': 'logistic'}\n",
      "0.6282\n",
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 100, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100), 'activation': 'relu'}\n",
      "0.626\n",
      "{'tol': 0.001, 'solver': 'adam', 'max_iter': 100, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'activation': 'logistic'}\n",
      "0.6259\n",
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 100, 'learning_rate_init': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100), 'activation': 'logistic'}\n",
      "0.6295\n",
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 150, 'learning_rate_init': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'activation': 'logistic'}\n",
      "0.6265\n",
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 150, 'learning_rate_init': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'activation': 'tanh'}\n",
      "0.6293\n",
      "{'tol': 0.0001, 'solver': 'adam', 'max_iter': 200, 'learning_rate_init': 0.0001, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (100, 100, 100), 'activation': 'logistic'}\n",
      "0.6298\n",
      "{'tol': 0.01, 'solver': 'adam', 'max_iter': 150, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100), 'activation': 'relu'}\n",
      "0.6266\n",
      "{'tol': 0.001, 'solver': 'adam', 'max_iter': 150, 'learning_rate_init': 0.0001, 'learning_rate': 'constant', 'hidden_layer_sizes': (100, 100, 100, 100), 'activation': 'tanh'}\n",
      "0.629\n"
     ]
    }
   ],
   "source": [
    "for idx_trial in range(n_repeats):\n",
    "    print(results[idx_trial]['params'][best_model_list[idx_trial]]), print(results[idx_trial]['mean_test_score'][best_model_list[idx_trial]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f148c69a7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(21./2.5, 4./2.5))\n",
    "\n",
    "counter = 1\n",
    "for idx_type in ['bare'] + estimatortype:\n",
    "    \n",
    "    if idx_type is not None:\n",
    "        \n",
    "        ax = fig.add_subplot(1, 3, counter)\n",
    "        ax.hist(vars()['acc_'+idx_type])\n",
    "        ax.set(xlabel='Accuracy', ylabel='Counts', title=idx_type)\n",
    "        \n",
    "        counter += 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fit_time = np.zeros(n_repeats)\n",
    "mean_score_time = np.zeros(n_repeats)\n",
    "mean_train_score = np.zeros(n_repeats)\n",
    "mean_test_score = np.zeros(n_repeats)\n",
    "cv_test_score = np.zeros((n_repeats, cv))\n",
    "cv_train_score = np.zeros((n_repeats, cv))\n",
    "\n",
    "for idx_rept in range(n_repeats):\n",
    "    \n",
    "    best_model = best_model_list[idx_rept]\n",
    "    \n",
    "    mean_fit_time[idx_rept] = results[idx_rept][\"mean_fit_time\"][best_model]\n",
    "    mean_score_time[idx_rept] = results[idx_rept][\"mean_score_time\"][best_model]\n",
    "    mean_train_score[idx_rept] = results[idx_rept][\"mean_train_score\"][best_model]\n",
    "    mean_test_score[idx_rept] = results[idx_rept][\"mean_test_score\"][best_model]\n",
    "    \n",
    "    for idx_cv in range(cv):\n",
    "        \n",
    "        cv_test_score[idx_rept, idx_cv] = results[idx_rept]['split'+str(idx_cv)+'_test_score'][best_model]\n",
    "        cv_train_score[idx_rept, idx_cv] = results[idx_rept]['split'+str(idx_cv)+'_train_score'][best_model]\n",
    "        \n",
    "\n",
    "np.savez(clf_flag+'_'+str(data_flag), \n",
    "        mean_fit_time=mean_fit_time,\n",
    "        mean_score_time=mean_score_time,\n",
    "        mean_train_score=mean_train_score,\n",
    "        mean_test_score=mean_test_score,\n",
    "        cv_test_score=cv_test_score,\n",
    "        cv_train_score=cv_train_score,\n",
    "        best_model_list=best_model_list,\n",
    "        class_prob_list=class_prob_list,\n",
    "        rho_minus_list=rho_minus_list,\n",
    "        rho_plus_list=rho_plus_list,\n",
    "        runtimes=[startscript, processtime, traintime, endscript],\n",
    "        acc_bare=acc_bare,         \n",
    "        pi_list=pi_list,\n",
    "        cmatrix_list=cmatrix_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
