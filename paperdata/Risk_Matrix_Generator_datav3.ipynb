{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Data Generator _datav3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to convert simulated data (raw output) into risk scores and store these for each class of simulations each with their own parameter regimes. \"Run all cells\" will create a set of risk matrices stored in npz form in the './data/' folder. These matrices are then access for performance reporting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib\n",
    "sys.path.append('../qslam')\n",
    "\n",
    "from visualiserisk import *\n",
    "from qslamdesignparams import GRIDDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Regimes\n",
    "\n",
    "The set of parameters are given in the dictionary format, LOOPS_DICT, and used for analysis via ParamUpdater. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose defaults to match floor case (heights didn't work)\n",
    "TRUTHKWARGS = {}\n",
    "\n",
    "BARRIER_FLOOR = 0.25*np.pi\n",
    "BARRIER_HEIGHT = 0.75*np.pi\n",
    "FLOOR_RATIO = 0.4 # matches floor case\n",
    "\n",
    "TRUTHKWARGS[\"OneStepdheight\"] = {\"low\": BARRIER_FLOOR, \n",
    "                                 \"high\": BARRIER_HEIGHT} \n",
    "TRUTHKWARGS[\"OneStepdfloorarea\"] = FLOOR_RATIO \n",
    "\n",
    "prefix_list = ['2019_Jun_1D', '2019_Jun_2D', '2019_Jun_2D_Gssn'] # ,\n",
    "PATHDICT['pdir'] = './data_v3'\n",
    "loadpath = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# TURN OFF PARAMETER SCANS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "idx_prevar = 0 \n",
    "# Fix truth configurations\n",
    "meta_truth_floor_scan = [FLOOR_RATIO] # [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "lowscan = [BARRIER_FLOOR] # np.asarray([0.2]*5)*np.pi\n",
    "highscan = [BARRIER_HEIGHT] # np.asarray([0.2, 0.4, 0.6, 0.8, 1.0])*np.pi\n",
    "truth_step_scan = zip(lowscan, highscan)\n",
    "\n",
    "\n",
    "idx_noise_var = 0 \n",
    "# Fix to noiseless case\n",
    "noiseclasses = ['noiseless'] \n",
    "noisestrengths = [0.0]\n",
    "meta_noisevar_scan = zip(noiseclasses, noisestrengths)\n",
    "\n",
    "\n",
    "# Fix msmt scan - and turn it off!\n",
    "msmt_per_qubit_scan = [1] # [1, 2, 4, 5, 6, 8, 10, 15, 20, 25, 50]\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# NEW PARAMETER SCANS\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "meta_max_iter_scan = [ 5, 10, 15, 20, 25, 50, 75, 100, 125, 250]\n",
    "\n",
    "lambda_databse = np.load('./lambda_pairs_2.npz')\n",
    "lambda1 = list(lambda_databse['lambda_1']) # [0.99, 0.956, 0.922, 0.888, 0.854, 0.820, 0.786, 0.752, 0.718, 0.684, 0.65]\n",
    "lambda2 = list(lambda_databse['lambda_2']) # [0.977, 0.9752, 0.9734, 0.9716, 0.9698, 0.968, 0.9662, 0.9644, 0.9626, 0.9608, 0.959]\n",
    "lambda_scan = zip(lambda1, lambda2)\n",
    "\n",
    "LOOPS_DICT = {\"meta_truth_floor_scan\": meta_truth_floor_scan,\n",
    "              \"meta_max_iter_scan\":meta_max_iter_scan, \n",
    "              \"meta_noisevar_scan\": meta_noisevar_scan,\n",
    "              \"truth_step_scan\": truth_step_scan,\n",
    "              \"lambda_scan\":lambda_scan,\n",
    "              \"msmt_per_qubit_scan\": msmt_per_qubit_scan}\n",
    "\n",
    "ParamUpdater = DataCube(LOOPS_DICT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to find the './data/' folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk score generator script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made data file: ./data_v3/RISK_2019_Jun_1D_n_0_vset_0.npz\n",
      "Made data file: ./data_v3/RISK_2019_Jun_2D_n_0_vset_0.npz\n",
      "Data filenot loaded. Unique ID: 2019_Jun_2D_Gssn_n_0_vset_0_t_0_m_5_v_34\n",
      "Data filenot loaded. Unique ID: 2019_Jun_2D_Gssn_n_0_vset_0_t_0_m_9_v_34\n",
      "Made data file: ./data_v3/RISK_2019_Jun_2D_Gssn_n_0_vset_0.npz\n"
     ]
    }
   ],
   "source": [
    "# Data variables\n",
    "max_msmtvar = len(ParamUpdater.meta_max_iter_scan)\n",
    "max_var = max(len(ParamUpdater.lambda_scan), len(ParamUpdater.msmt_per_qubit_scan))\n",
    "\n",
    "\n",
    "for prefix in prefix_list:\n",
    "\n",
    "    # simplify parameter scans by removing loops\n",
    "    max_prevar_floor = len(ParamUpdater.truth_step_scan) # no truth loop for any prefix\n",
    "    idx_prevar=0 # no truth loop, as stated above.\n",
    "    idx_noise_var=0 # no noise strength loop.\n",
    "    idx_var_dict=0 # only lambda loop, no msmt per iteration loop.\n",
    "\n",
    "    full_data_matrix = np.zeros((max_prevar_floor, max_msmtvar, max_var, 2, 4))\n",
    "\n",
    "    for idx_msmt_var in range(max_msmtvar): # loop over max iterations\n",
    "\n",
    "        macro_performance = []\n",
    "\n",
    "        for idx_var in range(max_var): # loop over lambda values\n",
    "\n",
    "            regime_ID = prefix + '_n_' + str(idx_noise_var) +'_vset_' + str(idx_var_dict)\n",
    "            testcase_ID = regime_ID + '_t_' + str(idx_prevar) + '_m_' + str(idx_msmt_var)\n",
    "\n",
    "            unique_ID = loadpath + testcase_ID + '_v_' + str(idx_var)\n",
    "\n",
    "            PATHDICT[\"fle\"] = unique_ID\n",
    "\n",
    "            perf_metrics = np.zeros((2, 4))\n",
    "\n",
    "            try:\n",
    "                qslamdata = np.load(path_to_file(PATHDICT, flag='q'))\n",
    "                naivedata = np.load(path_to_file(PATHDICT, flag='n'))\n",
    "            except:\n",
    "                print \"Data filenot loaded. Unique ID:\", unique_ID\n",
    "                macro_performance.append(perf_metrics)\n",
    "                continue\n",
    "\n",
    "            perf_metrics[:, 0] = np.asarray([Metric.original_err_metric(data[\"macro_residuals\"]) for data in [qslamdata, naivedata]])\n",
    "            perf_metrics[:, 1] = np.asarray([Metric.err(data[\"macro_residuals\"]) for data in [qslamdata, naivedata]])\n",
    "            perf_metrics[:, 2] = np.asarray([Metric.rms(data[\"macro_residuals\"]) for data in [qslamdata, naivedata]])\n",
    "            perf_metrics[:, 3] = np.asarray([Metric.ssim(data)[0] for data in [qslamdata, naivedata]]) # returning ssim (raw) or deviations\n",
    "\n",
    "            macro_performance.append(perf_metrics)\n",
    "\n",
    "\n",
    "        full_data_matrix[idx_prevar, idx_msmt_var, :, :, :] = np.asarray(macro_performance)\n",
    "\n",
    "\n",
    "    datafile = PATHDICT['pdir']+'/RISK_' + regime_ID +'.npz'\n",
    "    np.savez(datafile, full_data_matrix=full_data_matrix)\n",
    "\n",
    "    print \"Made data file:\", datafile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
