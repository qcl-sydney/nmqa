{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from qslamr import *\n",
    "from model_design import INITIALDICT, GRIDDICT\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['QUBIT_1', 'QUBIT_3', 'QUBIT_2']\n",
      "[(4.0, 3.5), (1.7, 3.2), (1.0, 2.5)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyjj4zcxSxsFvZpYy/x+GHkH5+EgfxgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f34b63e8390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print GRIDDICT.keys()\n",
    "print GRIDDICT.values()\n",
    "\n",
    "GRIDDICT['QUBIT_3'] = (1.7, 3.2)\n",
    "INITIALDICT['P_ALPHA'] = 3\n",
    "INITIALDICT['P_BETA'] = 2\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"2D Qubit Grid\")\n",
    "for key in GRIDDICT.keys():\n",
    "    plt.scatter(GRIDDICT[key][0], GRIDDICT[key][1], label=key)\n",
    "plt.legend()\n",
    "plt.margins(0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def true_noise_map(x,y, mu_x=2., mu_y=3, var_x=1, var_y=1.5):\n",
    "    var = np.eye(2)\n",
    "    var[0,0] = var_x\n",
    "    var[1,1] = var_y\n",
    "    arg = ((x- mu_x)**2 + (y- mu_y)**2 )/ 2*np.norm\n",
    "    return noise_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positions = GRIDDICT.values()\n",
    "test = ParticleFilter(positions, **INITIALDICT)\n",
    "measurement_controls = [[1, 1]]*10 # an upstate on Qubit 1 and Qubit 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In InitializeParticles...\n",
      "\n",
      "...for NEXT Alpha particle initialised in set_init_alphaparticle ...\n",
      "... In set_init_alphaparticle...\n",
      "... ... the initial neighbourhoood is 6.0\n",
      "... ... the initial particle state is\n",
      "[-1.26676545  0.45457702  1.69709597  0.8988148  -1.31882093 -0.8351716\n",
      "  2.12425007  0.18882652  2.27478296  0.60594228  7.39994337  0.08717827]\n",
      "... EXIT set_init_alphaparticle\n",
      "\n",
      "\n",
      "...for NEXT Alpha particle initialised in set_init_alphaparticle ...\n",
      "... In set_init_alphaparticle...\n",
      "... ... the initial neighbourhoood is 6.0\n",
      "... ... the initial particle state is\n",
      "[-0.48269767  1.01797329 -0.52590117  0.07159853 -0.69501249 -0.13955673\n",
      "  0.9763874   0.89339668  2.6135463   0.23446124  4.60413763  5.31743175]\n",
      "... EXIT set_init_alphaparticle\n",
      "\n",
      "\n",
      "...for NEXT Alpha particle initialised in set_init_alphaparticle ...\n",
      "... In set_init_alphaparticle...\n",
      "... ... the initial neighbourhoood is 6.0\n",
      "... ... the initial particle state is\n",
      "[-0.17405844 -1.67706189  0.14133177 -0.95251177  0.57640775 -0.43931091\n",
      "  2.85216537  1.11081028  0.91890835  5.96345148  4.59307625  9.61396281]\n",
      "... EXIT set_init_alphaparticle\n",
      "\n",
      "... passing on AlphaSet.posterior_state to QubitGrid.state_vector... \n",
      "... checking alpha weights uniformly distributed...\n",
      "[ 0.33333333  0.33333333  0.33333333]\n",
      "... checking alpha_weights sum to 1 [check output] =  1.0\n",
      "EXIT InitializeParticles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " NEW MSMT\n",
      "\n",
      "\n",
      "In ReceiveMsmt...\n",
      "... setting QubitGrid with next physical msmt...d=1, at Qubit 1...\n",
      "... calc sample probability via sample_prob_from_msmts, prob_j [output] =  1.0\n",
      "... updating alpha particle likelihood dictionary for next physical msmt data\n",
      "\n",
      " ... In update_alpha_dictionary ...\n",
      " ... ...  In LIKELIHOOD_ALPHA[msmt_dj] - old value -  -10.0\n",
      " ... ...  In LIKELIHOOD_ALPHA[prob_j] - old value -  -10.0\n",
      " ... ...  In LIKELIHOOD_ALPHA[msmt_dj] - new value -  1\n",
      " ... ...  In LIKELIHOOD_ALPHA[prob_j] - new value -  1.0\n",
      " ... EXIT update_alpha_dictionary ...\n",
      "EXIT ReceiveMsmt\n",
      "\n",
      "\n",
      " PROPAGATE\n",
      "\n",
      "\n",
      "... In PropagateState...\n",
      "...for NEXT alpha particle\n",
      "\n",
      "... ... In sample_from_transition_dist\n",
      "... ... alpha particle state propagated to \n",
      "[-0.38792979  2.21237529  0.74331215 -0.16461053  1.21125039  1.2867466   1.\n",
      "  1.          1.         -1.89924351 -0.53596837  0.18582524]\n",
      "... ... EXIT sample_from_transition_dist\n",
      "\n",
      "...for NEXT alpha particle\n",
      "\n",
      "... ... In sample_from_transition_dist\n",
      "... ... alpha particle state propagated to \n",
      "[ 1.29469097 -0.82459605 -0.72622177 -0.25886765 -1.26963157 -0.06815966\n",
      "  1.          1.          1.         -0.5839779  -0.12647378 -2.49036092]\n",
      "... ... EXIT sample_from_transition_dist\n",
      "\n",
      "...for NEXT alpha particle\n",
      "\n",
      "... ... In sample_from_transition_dist\n",
      "... ... alpha particle state propagated to \n",
      "[ 0.15878063 -0.12765533  0.9379538  -0.62009344 -0.64683019 -1.69363399\n",
      "  1.          1.          1.          0.02051428  0.86858914 -0.97342976]\n",
      "... ... EXIT sample_from_transition_dist\n",
      "\n",
      "... EXIT PropagateState\n",
      "\n",
      "\n",
      "\n",
      " COMPUTER WEIGHTS \n",
      "\n",
      "\n",
      "In ComputeWeights...\n",
      "\n",
      "\n",
      "... ... In alpha_weight_calc...\n",
      "\n",
      "... ... ... ... In likelihood_func_alpha...\n",
      "... ... ... ... ... From >>>, physical msmt, at j,  msmt_dj =  1\n",
      "... ... ... ... ... From >>>, sample probability , prob_j=  1.0\n",
      "... ... ... ... ... From INITDICT, variance , var_r =  1.0\n",
      "... ... ... ... ... With analytic rho_0 for b=1/2 is rho_0=  0.368746380373\n",
      "... ... ... ... ... This gives a likelihood for alpha particle = 0.553119570559\n",
      "... ... ... ... EXIT likelihood_func_alpha\n",
      "... ... ..., old_weight 0.333333333333\n",
      "... ... ..., likelihood 0.553119570559\n",
      "... ... ..., new_raw_weight 0.184373190186\n",
      "... ... EXIT alpha_weight_calc\n",
      "\n",
      "\n",
      "... ... In alpha_weight_calc...\n",
      "\n",
      "... ... ... ... In likelihood_func_alpha...\n",
      "... ... ... ... ... From >>>, physical msmt, at j,  msmt_dj =  1\n",
      "... ... ... ... ... From >>>, sample probability , prob_j=  1.0\n",
      "... ... ... ... ... From INITDICT, variance , var_r =  1.0\n",
      "... ... ... ... ... With analytic rho_0 for b=1/2 is rho_0=  0.368746380373\n",
      "... ... ... ... ... This gives a likelihood for alpha particle = 0.553119570559\n",
      "... ... ... ... EXIT likelihood_func_alpha\n",
      "... ... ..., old_weight 0.333333333333\n",
      "... ... ..., likelihood 0.553119570559\n",
      "... ... ..., new_raw_weight 0.184373190186\n",
      "... ... EXIT alpha_weight_calc\n",
      "\n",
      "\n",
      "... ... In alpha_weight_calc...\n",
      "\n",
      "... ... ... ... In likelihood_func_alpha...\n",
      "... ... ... ... ... From >>>, physical msmt, at j,  msmt_dj =  1\n",
      "... ... ... ... ... From >>>, sample probability , prob_j=  1.0\n",
      "... ... ... ... ... From INITDICT, variance , var_r =  1.0\n",
      "... ... ... ... ... With analytic rho_0 for b=1/2 is rho_0=  0.368746380373\n",
      "... ... ... ... ... This gives a likelihood for alpha particle = 0.553119570559\n",
      "... ... ... ... EXIT likelihood_func_alpha\n",
      "... ... ..., old_weight 0.333333333333\n",
      "... ... ..., likelihood 0.553119570559\n",
      "... ... ..., new_raw_weight 0.184373190186\n",
      "... ... EXIT alpha_weight_calc\n",
      "\n",
      "... Calculating the first set of weights  for alpha particles based on physical msmts\n",
      "[ 0.33333333  0.33333333  0.33333333]\n",
      "... (these new weightts are set as alpha particle weights, and equal to the below:)\n",
      "[ 0.33333333  0.33333333  0.33333333]\n",
      " \n",
      "... Calculating the second set of weights for beta particles for each alpha...\n",
      "\n",
      "... for NEXT alpha particle: ...\n",
      "\n",
      "... ... Updating particle map via update_alpha_map_via_born_rule...\n",
      "\n",
      "... ... Calculating beta*alpha weights via beta_alpha_j_weights...\n",
      "\n",
      "\n",
      "... ... ... In generate_beta_layer...\n",
      "\n",
      "... ... ... Copying parent alpha state and generating beta particles...\n",
      "... ... ... Parent state is [output]\n",
      "[-0.38792979  2.21237529  0.74331215 -0.16461053  1.21125039  1.2867466   1.\n",
      "  0.          1.         -1.89924351 -0.53596837  0.18582524]\n",
      "\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] -0.53596836573\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 2.6530436472\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 2.6530436472\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 2.16882419034\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 2.16882419034\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 2.76874266978\n",
      "\n",
      "... ... ... Storing a list_of_parent_states =\n",
      "... ... ... Generating a beta particle list from list of parent states\n",
      "\n",
      "... ... ... Check size of betaset for alpha post generate_beta_pset = 3\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... Calculate bset weights based on beta likelihood functiion...\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... Check the shape of output  (3,)\n",
      "... ... ... Check normalisation beta_alpha_j_weights  1.0\n",
      "... ... ... RETURN beta_alpha_j_weights  (3,)\n",
      "\n",
      "... ... ... EXIT generate_beta_layer\n",
      "\n",
      "... ... Raw posterior beta alpha weights are [ 0.33333333  0.33333333  0.33333333]\n",
      "\n",
      "... for NEXT alpha particle: ...\n",
      "\n",
      "... ... Updating particle map via update_alpha_map_via_born_rule...\n",
      "\n",
      "... ... Calculating beta*alpha weights via beta_alpha_j_weights...\n",
      "\n",
      "\n",
      "... ... ... In generate_beta_layer...\n",
      "\n",
      "... ... ... Copying parent alpha state and generating beta particles...\n",
      "... ... ... Parent state is [output]\n",
      "[ 1.29469097 -0.82459605 -0.72622177 -0.25886765 -1.26963157 -0.06815966\n",
      "  1.          0.          1.         -0.5839779  -0.12647378 -2.49036092]\n",
      "\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] -0.126473784676\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 3.65204726338\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 3.65204726338\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 0.867157862163\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 0.867157862163\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 0.0908241252808\n",
      "\n",
      "... ... ... Storing a list_of_parent_states =\n",
      "... ... ... Generating a beta particle list from list of parent states\n",
      "\n",
      "... ... ... Check size of betaset for alpha post generate_beta_pset = 3\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... Calculate bset weights based on beta likelihood functiion...\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.398942280401\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.398942280401\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.398942280401\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... Check the shape of output  (3,)\n",
      "... ... ... Check normalisation beta_alpha_j_weights  1.0\n",
      "... ... ... RETURN beta_alpha_j_weights  (3,)\n",
      "\n",
      "... ... ... EXIT generate_beta_layer\n",
      "\n",
      "... ... Raw posterior beta alpha weights are [ 0.33333333  0.33333333  0.33333333]\n",
      "\n",
      "... for NEXT alpha particle: ...\n",
      "\n",
      "... ... Updating particle map via update_alpha_map_via_born_rule...\n",
      "\n",
      "... ... Calculating beta*alpha weights via beta_alpha_j_weights...\n",
      "\n",
      "\n",
      "... ... ... In generate_beta_layer...\n",
      "\n",
      "... ... ... Copying parent alpha state and generating beta particles...\n",
      "... ... ... Parent state is [output]\n",
      "[ 0.15878063 -0.12765533  0.9379538  -0.62009344 -0.64683019 -1.69363399\n",
      "  1.          0.          1.          0.02051428  0.86858914 -0.97342976]\n",
      "\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 0.868589139909\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 2.54712976894\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 2.54712976894\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 1.43458708754\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 1.43458708754\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 0.938239238387\n",
      "\n",
      "... ... ... Storing a list_of_parent_states =\n",
      "... ... ... Generating a beta particle list from list of parent states\n",
      "\n",
      "... ... ... Check size of betaset for alpha post generate_beta_pset = 3\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... Calculate bset weights based on beta likelihood functiion...\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... Check the shape of output  (3,)\n",
      "... ... ... Check normalisation beta_alpha_j_weights  1.0\n",
      "... ... ... RETURN beta_alpha_j_weights  (3,)\n",
      "\n",
      "... ... ... EXIT generate_beta_layer\n",
      "\n",
      "... ... Raw posterior beta alpha weights are [ 0.33333333  0.33333333  0.33333333]\n",
      "... Calculating posterior normalisation ... 1.0\n",
      "\n",
      "... The normalised_posterior_weights are  [ 0.11111111  0.11111111  0.11111111  0.11111111  0.11111111  0.11111111\n",
      "  0.11111111  0.11111111  0.11111111]\n",
      "\n",
      "EXIT ComputeWeights \n",
      "\n",
      "\n",
      " RESAMPLE\n",
      "\n",
      "\n",
      "In ResampleParticles ...\n",
      " ... Checking resamplign threshold using effective_particle_size ...\n",
      "\n",
      "... In effective_particle_size, posterior_weights:\n",
      "[ 0.11111111  0.11111111  0.11111111  0.11111111  0.11111111  0.11111111\n",
      "  0.11111111  0.11111111  0.11111111]\n",
      "\n",
      "... ... The variance of these posterior weights is  0.111111111111\n",
      "... ... The p_size of these posterior weights is  9.0\n",
      "... ... The self.L_factor of these posterior weights is  36.0\n",
      "\n",
      "... EXIT effective_particle_size \n",
      "\n",
      "In resample_constant_pset_alpha, number of sufficient samples are: 8\n",
      "\n",
      "... In collapse_beta...\n",
      "... ... The subtree is defined by the endpoint index boundaries [0, 0]\n",
      "... ... The leaves of the subtree are  []\n",
      "... ... The subtree is defined by the endpoint index boundaries [0, 3]\n",
      "... ... The leaves of the subtree are  [2, 2, 2]\n",
      "... ... The subtree has alpha node of:  0\n",
      "... ... The leaves of the subtree are labeled by beta indices [2, 2, 2]\n",
      "... ... Collapsing the beta layers for new alpha particles\n",
      "... ... The subtree is defined by the endpoint index boundaries [3, 6]\n",
      "... ... The leaves of the subtree are  [3, 4, 5]\n",
      "... ... The subtree has alpha node of:  1\n",
      "... ... The leaves of the subtree are labeled by beta indices [0, 1, 2]\n",
      "... ... Collapsing the beta layers for new alpha particles\n",
      "... ... The subtree is defined by the endpoint index boundaries [6, 8]\n",
      "... ... The leaves of the subtree are  [8, 8]\n",
      "... ... The subtree has alpha node of:  2\n",
      "... ... The leaves of the subtree are labeled by beta indices [2, 2]\n",
      "... ... Collapsing the beta layers for new alpha particles\n",
      "... EXIT collapse_beta\n",
      "\n",
      "\n",
      "...The new list of alphat particles should be same as previously: self.pset_alpha = 3, new list = 3\n",
      "... Setting AlphaSet.particles  to new particles without a beta layer; and uniform weights\n",
      "\n",
      "EXIT ResampleParticles\n",
      "\n",
      "\n",
      " QUASI MSMT\n",
      "\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "\n",
      "\n",
      " NEW MSMT\n",
      "\n",
      "\n",
      "In ReceiveMsmt...\n",
      "... setting QubitGrid with next physical msmt...d=1, at Qubit 1...\n",
      "... calc sample probability via sample_prob_from_msmts, prob_j [output] =  1.9801\n",
      "... updating alpha particle likelihood dictionary for next physical msmt data\n",
      "\n",
      " ... In update_alpha_dictionary ...\n",
      " ... ...  In LIKELIHOOD_ALPHA[msmt_dj] - old value -  1\n",
      " ... ...  In LIKELIHOOD_ALPHA[prob_j] - old value -  1.0\n",
      " ... ...  In LIKELIHOOD_ALPHA[msmt_dj] - new value -  1\n",
      " ... ...  In LIKELIHOOD_ALPHA[prob_j] - new value -  1.9801\n",
      " ... EXIT update_alpha_dictionary ...\n",
      "EXIT ReceiveMsmt\n",
      "\n",
      "\n",
      " PROPAGATE\n",
      "\n",
      "\n",
      "... In PropagateState...\n",
      "...for NEXT alpha particle\n",
      "\n",
      "... ... In sample_from_transition_dist\n",
      "... ... alpha particle state propagated to \n",
      "[ 0.94257172 -0.53574966  0.75914484  2.44842388  0.50944659 -1.12485427\n",
      "  1.          1.          1.         -0.02865584  1.3740702  -1.1543279 ]\n",
      "... ... EXIT sample_from_transition_dist\n",
      "\n",
      "...for NEXT alpha particle\n",
      "\n",
      "... ... In sample_from_transition_dist\n",
      "... ... alpha particle state propagated to \n",
      "[ 1.57425953 -0.76298519 -0.88764467  0.10777192 -0.43295633 -0.426007    1.\n",
      "  1.          1.          0.29941196 -0.96591121 -1.83186098]\n",
      "... ... EXIT sample_from_transition_dist\n",
      "\n",
      "...for NEXT alpha particle\n",
      "\n",
      "... ... In sample_from_transition_dist\n",
      "... ... alpha particle state propagated to \n",
      "[-1.01316026  0.79579121  1.53318994 -0.6670436  -0.8958536  -0.97883153\n",
      "  1.          1.          1.         -0.25973133  1.77418277  0.22835119]\n",
      "... ... EXIT sample_from_transition_dist\n",
      "\n",
      "... EXIT PropagateState\n",
      "\n",
      "\n",
      "\n",
      " COMPUTER WEIGHTS \n",
      "\n",
      "\n",
      "In ComputeWeights...\n",
      "\n",
      "\n",
      "... ... In alpha_weight_calc...\n",
      "\n",
      "... ... ... ... In likelihood_func_alpha...\n",
      "... ... ... ... ... From >>>, physical msmt, at j,  msmt_dj =  1\n",
      "... ... ... ... ... From >>>, sample probability , prob_j=  1.9801\n",
      "... ... ... ... ... From INITDICT, variance , var_r =  1.0\n",
      "... ... ... ... ... With analytic rho_0 for b=1/2 is rho_0=  0.368746380373\n",
      "... ... ... ... ... This gives a likelihood for alpha particle = 1.27593622536\n",
      "... ... ... ... EXIT likelihood_func_alpha\n",
      "... ... ..., old_weight 0.333333333333\n",
      "... ... ..., likelihood 1.27593622536\n",
      "... ... ..., new_raw_weight 0.425312075122\n",
      "... ... EXIT alpha_weight_calc\n",
      "\n",
      "\n",
      "... ... In alpha_weight_calc...\n",
      "\n",
      "... ... ... ... In likelihood_func_alpha...\n",
      "... ... ... ... ... From >>>, physical msmt, at j,  msmt_dj =  1\n",
      "... ... ... ... ... From >>>, sample probability , prob_j=  1.9801\n",
      "... ... ... ... ... From INITDICT, variance , var_r =  1.0\n",
      "... ... ... ... ... With analytic rho_0 for b=1/2 is rho_0=  0.368746380373\n",
      "... ... ... ... ... This gives a likelihood for alpha particle = 1.27593622536\n",
      "... ... ... ... EXIT likelihood_func_alpha\n",
      "... ... ..., old_weight 0.333333333333\n",
      "... ... ..., likelihood 1.27593622536\n",
      "... ... ..., new_raw_weight 0.425312075122\n",
      "... ... EXIT alpha_weight_calc\n",
      "\n",
      "\n",
      "... ... In alpha_weight_calc...\n",
      "\n",
      "... ... ... ... In likelihood_func_alpha...\n",
      "... ... ... ... ... From >>>, physical msmt, at j,  msmt_dj =  1\n",
      "... ... ... ... ... From >>>, sample probability , prob_j=  1.9801\n",
      "... ... ... ... ... From INITDICT, variance , var_r =  1.0\n",
      "... ... ... ... ... With analytic rho_0 for b=1/2 is rho_0=  0.368746380373\n",
      "... ... ... ... ... This gives a likelihood for alpha particle = 1.27593622536\n",
      "... ... ... ... EXIT likelihood_func_alpha\n",
      "... ... ..., old_weight 0.333333333333\n",
      "... ... ..., likelihood 1.27593622536\n",
      "... ... ..., new_raw_weight 0.425312075122\n",
      "... ... EXIT alpha_weight_calc\n",
      "\n",
      "... Calculating the first set of weights  for alpha particles based on physical msmts\n",
      "[ 0.33333333  0.33333333  0.33333333]\n",
      "... (these new weightts are set as alpha particle weights, and equal to the below:)\n",
      "[ 0.33333333  0.33333333  0.33333333]\n",
      " \n",
      "... Calculating the second set of weights for beta particles for each alpha...\n",
      "\n",
      "... for NEXT alpha particle: ...\n",
      "\n",
      "... ... Updating particle map via update_alpha_map_via_born_rule...\n",
      "\n",
      "... ... Calculating beta*alpha weights via beta_alpha_j_weights...\n",
      "\n",
      "\n",
      "... ... ... In generate_beta_layer...\n",
      "\n",
      "... ... ... Copying parent alpha state and generating beta particles...\n",
      "... ... ... Parent state is [output]\n",
      "[ 0.94257172 -0.53574966  0.75914484  2.44842388  0.50944659 -1.12485427\n",
      "  1.                 nan  1.         -0.02865584  1.3740702  -1.1543279 ]\n",
      "\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 1.37407020331\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 13.6674456988\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 13.6674456988\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 18.800445698\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 18.800445698\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 17.2466573777\n",
      "\n",
      "... ... ... Storing a list_of_parent_states =\n",
      "... ... ... Generating a beta particle list from list of parent states\n",
      "\n",
      "... ... ... Check size of betaset for alpha post generate_beta_pset = 3\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... Calculate bset weights based on beta likelihood functiion...\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... Check the shape of output  (3,)\n",
      "... ... ... Check normalisation beta_alpha_j_weights  1.0\n",
      "... ... ... RETURN beta_alpha_j_weights  (3,)\n",
      "\n",
      "... ... ... EXIT generate_beta_layer\n",
      "\n",
      "... ... Raw posterior beta alpha weights are [ 0.33333333  0.33333333  0.33333333]\n",
      "\n",
      "... for NEXT alpha particle: ...\n",
      "\n",
      "... ... Updating particle map via update_alpha_map_via_born_rule...\n",
      "\n",
      "... ... Calculating beta*alpha weights via beta_alpha_j_weights...\n",
      "\n",
      "\n",
      "... ... ... In generate_beta_layer...\n",
      "\n",
      "... ... ... Copying parent alpha state and generating beta particles...\n",
      "... ... ... Parent state is [output]\n",
      "[ 1.57425953 -0.76298519 -0.88764467  0.10777192 -0.43295633 -0.426007    1.\n",
      "         nan  1.          0.29941196 -0.96591121 -1.83186098]\n",
      "\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] -0.965911207169\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 21.9563046926\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 21.9563046926\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 2.18893621928\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 2.18893621928\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 19.5578380816\n",
      "\n",
      "... ... ... Storing a list_of_parent_states =\n",
      "... ... ... Generating a beta particle list from list of parent states\n",
      "\n",
      "... ... ... Check size of betaset for alpha post generate_beta_pset = 3\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... Calculate bset weights based on beta likelihood functiion...\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... Check the shape of output  (3,)\n",
      "... ... ... Check normalisation beta_alpha_j_weights  1.0\n",
      "... ... ... RETURN beta_alpha_j_weights  (3,)\n",
      "\n",
      "... ... ... EXIT generate_beta_layer\n",
      "\n",
      "... ... Raw posterior beta alpha weights are [ 0.33333333  0.33333333  0.33333333]\n",
      "\n",
      "... for NEXT alpha particle: ...\n",
      "\n",
      "... ... Updating particle map via update_alpha_map_via_born_rule...\n",
      "\n",
      "... ... Calculating beta*alpha weights via beta_alpha_j_weights...\n",
      "\n",
      "\n",
      "... ... ... In generate_beta_layer...\n",
      "\n",
      "... ... ... Copying parent alpha state and generating beta particles...\n",
      "... ... ... Parent state is [output]\n",
      "[-1.01316026  0.79579121  1.53318994 -0.6670436  -0.8958536  -0.97883153\n",
      "  1.                 nan  1.         -0.25973133  1.77418277  0.22835119]\n",
      "\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 1.77418277331\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 28.4056970674\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 28.4056970674\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 25.312961589\n",
      "\n",
      "... ... ... for NEXT beta particle ...\n",
      "... ... ... ... parent state length [before] 25.312961589\n",
      "... ... ... ... sample a new length scale...\n",
      "... ... ... ... parent state length [after] 23.9310917276\n",
      "\n",
      "... ... ... Storing a list_of_parent_states =\n",
      "... ... ... Generating a beta particle list from list of parent states\n",
      "\n",
      "... ... ... Check size of betaset for alpha post generate_beta_pset = 3\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... for NEXT beta particle\n",
      "... ... ... ... Make a neighbourhood of qubits for each beta using new lengthscale sample...\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n",
      "... ... ... Calculate bset weights based on beta likelihood functiion...\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... In beta_weight_calc ...\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "\n",
      "... ... ... ... In likelihood_func_beta ... with mean, variance =  0.0 1.0\n",
      "... ... ... ... ... The new_phase at q based on smearing from physical msmt info at j: 0.0\n",
      "... ... ... ... ... The old_phase at q based on posterior QubitGrid at q, at t-1: 0.0\n",
      "... ... ... ... ... Likelihood contribution at q: result =  0.398942280401\n",
      "... ... ... ... EXIT likelihood_func_beta ...\n",
      "\n",
      "... ... ... The likelihood over all qubits in beta neighbourhood is: [0.3989422804014327, 0.3989422804014327, 0.3989422804014327]\n",
      "... ... ... The net_likelihood is: 0.0634936359342\n",
      "... ... ... EXIT beta_weight_calc\n",
      "\n",
      "... ... ... Check the shape of output  (3,)\n",
      "... ... ... Check normalisation beta_alpha_j_weights  1.0\n",
      "... ... ... RETURN beta_alpha_j_weights  (3,)\n",
      "\n",
      "... ... ... EXIT generate_beta_layer\n",
      "\n",
      "... ... Raw posterior beta alpha weights are [ 0.33333333  0.33333333  0.33333333]\n",
      "... Calculating posterior normalisation ... 1.0\n",
      "\n",
      "... The normalised_posterior_weights are  [ 0.11111111  0.11111111  0.11111111  0.11111111  0.11111111  0.11111111\n",
      "  0.11111111  0.11111111  0.11111111]\n",
      "\n",
      "EXIT ComputeWeights \n",
      "\n",
      "\n",
      " RESAMPLE\n",
      "\n",
      "\n",
      "In ResampleParticles ...\n",
      " ... Checking resamplign threshold using effective_particle_size ...\n",
      "\n",
      "... In effective_particle_size, posterior_weights:\n",
      "[ 0.11111111  0.11111111  0.11111111  0.11111111  0.11111111  0.11111111\n",
      "  0.11111111  0.11111111  0.11111111]\n",
      "\n",
      "... ... The variance of these posterior weights is  0.111111111111\n",
      "... ... The p_size of these posterior weights is  9.0\n",
      "... ... The self.L_factor of these posterior weights is  36.0\n",
      "\n",
      "... EXIT effective_particle_size \n",
      "\n",
      "In resample_constant_pset_alpha, number of sufficient samples are: 8\n",
      "\n",
      "... In collapse_beta...\n",
      "... ... The subtree is defined by the endpoint index boundaries [0, 0]\n",
      "... ... The leaves of the subtree are  []\n",
      "... ... The subtree is defined by the endpoint index boundaries [0, 4]\n",
      "... ... The leaves of the subtree are  [0, 0, 1, 2]\n",
      "... ... The subtree has alpha node of:  0\n",
      "... ... The leaves of the subtree are labeled by beta indices [0, 0, 1, 2]\n",
      "... ... Collapsing the beta layers for new alpha particles\n",
      "... ... The subtree is defined by the endpoint index boundaries [4, 6]\n",
      "... ... The leaves of the subtree are  [3, 4]\n",
      "... ... The subtree has alpha node of:  1\n",
      "... ... The leaves of the subtree are labeled by beta indices [0, 1]\n",
      "... ... Collapsing the beta layers for new alpha particles\n",
      "... ... The subtree is defined by the endpoint index boundaries [6, 8]\n",
      "... ... The leaves of the subtree are  [6, 7]\n",
      "... ... The subtree has alpha node of:  2\n",
      "... ... The leaves of the subtree are labeled by beta indices [0, 1]\n",
      "... ... Collapsing the beta layers for new alpha particles\n",
      "... EXIT collapse_beta\n",
      "\n",
      "\n",
      "...The new list of alphat particles should be same as previously: self.pset_alpha = 3, new list = 3\n",
      "... Setting AlphaSet.particles  to new particles without a beta layer; and uniform weights\n",
      "\n",
      "EXIT ResampleParticles\n",
      "\n",
      "\n",
      " QUASI MSMT\n",
      "\n",
      "... ... ... ... In generate_beta_neighbourhood...\n",
      "... ... ... ...  Pull information about the posterior state from t-1 QubitGrid...\n",
      "... ... ... ...  Smear phases in beta particle neighbood...\n",
      "\n",
      "... ... ... ... EXIT generate_beta_neighbourhood\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qslamr.py:136: RuntimeWarning: invalid value encountered in arccos\n",
      "  map_val = np.arccos(2.0*born_prob  - 1.0)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "p is nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d496d2586bfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqslamr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeasurement_controls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/riddhisw/Documents/SLAM_project/qslam/qslamr.pyc\u001b[0m in \u001b[0;36mqslamr\u001b[0;34m(self, measurements_controls)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_qubitgrid_via_quasimsmts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol_j\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;31m#       ------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/riddhisw/Documents/SLAM_project/qslam/qslamr.pyc\u001b[0m in \u001b[0;36mupdate_qubitgrid_via_quasimsmts\u001b[0;34m(self, control_j, posterior_state)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mquasi_phase_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSmearParticle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmeared_phases_qj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mborn_prob_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParticleFilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mborn_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquasi_phase_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mquasi_msmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mborn_prob_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQubitGrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneighbour_q\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquasimsmtsum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquasi_msmt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.binomial (numpy/random/mtrand/mtrand.c:30446)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: p is nan"
     ]
    }
   ],
   "source": [
    "test.qslamr(measurement_controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the subtree generation - particularly the last tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing whether the resamplign function picks out all indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Resample(object):\n",
    "    '''docstring'''\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def resample_from_weights(posterior_weights, number_of_samples):\n",
    "        '''docstring'''\n",
    "        total_particles = len(posterior_weights)\n",
    "        cdf_weights = np.asarray([0] + [np.sum(posterior_weights[:idx+1]) for idx in range(total_particles)])\n",
    "        pdf_uniform = np.random.uniform(low=0, high=1.0, size=number_of_samples)\n",
    "\n",
    "        resampled_idx = []\n",
    "\n",
    "        for u_0 in pdf_uniform:\n",
    "            j = 0\n",
    "            while u_0 > cdf_weights[j]:\n",
    "                j += 1\n",
    "                if j > total_particles:\n",
    "                    j = total_particles \n",
    "                    # print('Break - max particle index reached during sampling')\n",
    "                    break   # clip at max particle index, plus zero\n",
    "            resampled_idx.append(j-1) # sgift down to match python indices\n",
    "\n",
    "        return resampled_idx    \n",
    "    \n",
    "    @staticmethod\n",
    "    def get_subtrees(resampled_indices, pset_beta):\n",
    "        '''docstring'''\n",
    "    \n",
    "        new_sub_trees = []\n",
    "\n",
    "        resampled_indices.sort()\n",
    "        alpha_index_0 = None\n",
    "        strt_counter=0\n",
    "        end_counter=0\n",
    "\n",
    "        for idx in resampled_indices:\n",
    "\n",
    "            alpha_index = Resample.get_alpha_node_from_treeleaf(idx, pset_beta)\n",
    "            beta_alpha_idx = Resample.get_beta_node_from_treeleaf(idx, pset_beta)\n",
    "\n",
    "            if alpha_index_0 == alpha_index:\n",
    "                end_counter +=1\n",
    "\n",
    "            elif alpha_index_0 != alpha_index:\n",
    "\n",
    "                new_sub_trees.append([strt_counter, end_counter])\n",
    "\n",
    "                alpha_index_0 = alpha_index\n",
    "                strt_counter = end_counter\n",
    "                end_counter += 1\n",
    "\n",
    "        if end_counter == len(resampled_indices):\n",
    "            end_counter += 1\n",
    "            new_sub_trees.append([strt_counter, end_counter])\n",
    "\n",
    "        return new_sub_trees\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_alpha_node_from_treeleaf(leaf_index, pset_beta):\n",
    "        '''docstring'''\n",
    "        alpha_node = int(leaf_index//float(pset_beta))\n",
    "        return alpha_node\n",
    "\n",
    "    @staticmethod\n",
    "    def get_beta_node_from_treeleaf(leaf_index, pset_beta):\n",
    "        '''docstring'''\n",
    "        beta_node = int(leaf_index - int(leaf_index//float(pset_beta))*pset_beta)\n",
    "        return beta_node\n",
    "    \n",
    "    @staticmethod\n",
    "    def collapse_beta(subtree_list, resampled_indices, pset_beta):\n",
    "        '''docstring'''\n",
    "\n",
    "        state_update = 0.\n",
    "        new_alpha_particle_list = []\n",
    "        \n",
    "        for subtree in subtree_list:\n",
    "\n",
    "            leaves_of_subtree = resampled_indices[subtree[0]:subtree[1]]\n",
    "            leaf_count = float(len(leaves_of_subtree))\n",
    "            print \"The subtree is defined by the endpoint index boundaries\", subtree\n",
    "            print \"The leaves of the subtree are \", leaves_of_subtree\n",
    "\n",
    "            if leaf_count != 0:\n",
    "\n",
    "                normaliser = (1./leaf_count)\n",
    "                alpha_node = Resample.get_alpha_node_from_treeleaf(leaves_of_subtree[0], pset_beta)\n",
    "                               # resampled_indices[subtree[0]], pset_beta)\n",
    "                beta_alpha_nodes = [Resample.get_beta_node_from_treeleaf(leafy, pset_beta) for leafy in leaves_of_subtree]\n",
    "                               # resampled_indices[subtree[0]:subtree[1]]] \n",
    "                print \"The subtree has alpha node of: \", alpha_node \n",
    "                print \"The leaves of the subtree are labeled by beta indices\", beta_alpha_nodes\n",
    "                \n",
    "#                 r_est_subtree = 0.0\n",
    "#                 for node in beta_alpha_nodes:\n",
    "                    \n",
    "#                     beta_state = self.AlphaSet.particles[alpha_node].BetaAlphaSet_j.particles[node].particle\n",
    "#                     node_j = self.AlphaSet.particles[alpha_node].node_j\n",
    "#                     beta_lengthscale = beta_state[int(node_j)]\n",
    "#                     r_est_subtree += normaliser*beta_lengthscale\n",
    "\n",
    "#                 parent = self.AlphaSet.particles[alpha_node].particle\n",
    "#                 parent[self.AlphaSet.particles[alpha_node].node_j] = r_est_subtree\n",
    "\n",
    "#                 # Beta Layer Collapsed\n",
    "#                 self.AlphaSet.particles[alpha_node].particle = parent\n",
    "#                 self.AlphaSet.particles[alpha_node].BetaAlphaSet_j = None\n",
    "\n",
    "#                 # New Alphas Stored\n",
    "#                 new_alpha_particle_list.append(self.AlphaSet.particles[alpha_node])\n",
    "#         print\n",
    "#         return new_alpha_particle_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pset_alpha=2 #0 ==== 1==== 2 ===\n",
    "pset_beta=2 #0, 1 == 2, 3, == 4,5\n",
    "particles = pset_beta*pset_alpha\n",
    "posterior_weights = list((1.0 / float(particles))*np.ones(particles))\n",
    "number_of_samples = 10\n",
    "\n",
    "resampled = Resample.resample_from_weights(posterior_weights, number_of_samples)\n",
    "alphas = [Resample.get_alpha_node_from_treeleaf(index, pset_beta) for index in resampled]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.hist(resampled, bins=len(posterior_weights))\n",
    "plt.show()\n",
    "\n",
    "print \"unique values\", set(list(alphas))\n",
    "print \"resamp\", resampled\n",
    "print \"alphas\", alphas\n",
    "print len( set(list(resampled))) == particles\n",
    "print len( set(list(alphas))) == pset_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subtree_boundaries = Resample.get_subtrees(resampled, pset_beta)\n",
    "print subtree_boundaries\n",
    "\n",
    "for subtree in subtree_boundaries:\n",
    "    #alpha_node = Resample.get_alpha_node_from_treeleaf(pairs[0], pset_beta)\n",
    "    #beta_alpha_nodes = [Resample.get_beta_node_from_treeleaf(leafy, pset_beta) for leafy in subtree]\n",
    "    print \n",
    "    print \"The subtree endpoints are\", subtree\n",
    "    print \"The leaves of the subtree are \", resampled[subtree[0]:subtree[1]]\n",
    "    print \"The subtree has alpha node of: \", Resample.get_alpha_node_from_treeleaf(resampled[subtree[0]], pset_beta)\n",
    "    print \"The leaves of the subtree are labeled by beta indices\", [Resample.get_beta_node_from_treeleaf(leafy, pset_beta) for leafy in resampled[subtree[0]:subtree[1]]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Resample.collapse_beta(subtree_boundaries, resampled, pset_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test unpacking of a slice of an array into elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = 3\n",
    "statetype = 4\n",
    "a = range(nodes*statetype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[0::nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a[1::nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y, z, r = a[2::nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the flattening of lists into arrays - cases of success and failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [[3.4, 2.0],[2, 1]]\n",
    "y = [[3.4],[2, 1]]\n",
    "z = [3.4,[2, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(x).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(y).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.asarray(z).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
