{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk Data Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to convert simulated data (raw output) into risk scores and store these for each class of simulations each with their own parameter regimes. \"Run all cells\" will create a set of risk matrices stored in npz form in the './data/' folder. These matrices are then access for performance reporting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib\n",
    "sys.path.append('../')\n",
    "\n",
    "from visualiserisk import *\n",
    "from qslamdesignparams import GRIDDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Regimes\n",
    "\n",
    "The set of parameters are given in the dictionary format, LOOPS_DICT, and used for analysis via ParamUpdater. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meta_truth_floor_scan = [0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "meta_max_iter_scan = [ 5, 10, 15, 20, 25, 50, 75, 100, 125, 250]\n",
    "\n",
    "noiseclasses = ['noiseless'] + ['alwaysdark', 'spnoise']*4\n",
    "noisestrengths = [0.0, 0.1, 0.1, 0.2, 0.2, 0.3, 0.3, 0.5, 0.5]*2 # shouldnt be a 2 but hopefully doesnt matter\n",
    "meta_noisevar_scan = zip(noiseclasses, noisestrengths)\n",
    "\n",
    "lowscan = np.asarray([0.2]*5)*np.pi\n",
    "highscan = np.asarray([0.2, 0.4, 0.6, 0.8, 1.0])*np.pi\n",
    "truth_step_scan = zip(lowscan, highscan)\n",
    "\n",
    "\n",
    "lambda1 = [0.99, 0.956, 0.922, 0.888, 0.854, 0.820, 0.786, 0.752, 0.718, 0.684, 0.65]\n",
    "lambda2 = [0.977, 0.9752, 0.9734, 0.9716, 0.9698, 0.968, 0.9662, 0.9644, 0.9626, 0.9608, 0.959]\n",
    "lambda_scan = zip(lambda1, lambda2)\n",
    "msmt_per_qubit_scan = [1, 2, 4, 5, 6, 8, 10, 15, 20, 25, 50]\n",
    "\n",
    "msmt_per_qubit_scan = [1, 2, 4, 5, 6, 8, 10, 15, 20, 25, 50]\n",
    "\n",
    "\n",
    "LOOPS_DICT = {\"meta_truth_floor_scan\": meta_truth_floor_scan,\n",
    "              \"meta_max_iter_scan\":meta_max_iter_scan, \n",
    "              \"meta_noisevar_scan\": meta_noisevar_scan,\n",
    "              \"truth_step_scan\": truth_step_scan,\n",
    "              \"lambda_scan\":lambda_scan,\n",
    "              \"msmt_per_qubit_scan\": msmt_per_qubit_scan}\n",
    "\n",
    "ParamUpdater = DataCube(LOOPS_DICT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where to find the './data/' folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loadpath = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Risk score generator script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Made data file: ./data/RISK_NSL_tfloor_n_0_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_0_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_1_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_1_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_2_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_2_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_3_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_3_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_4_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_4_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_5_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_5_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_6_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_6_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_7_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_7_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_8_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_tfloor_n_8_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_0_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_0_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_1_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_1_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_2_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_2_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_3_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_3_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_4_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_4_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_5_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_5_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_6_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_6_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_7_vset_0.npz\n",
      "Data filenot loaded. Unique ID: NSL_theight_n_7_vset_1_t_2_m_9_v_10\n",
      "Made data file: ./data/RISK_NSL_theight_n_7_vset_1.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_8_vset_0.npz\n",
      "Made data file: ./data/RISK_NSL_theight_n_8_vset_1.npz\n"
     ]
    }
   ],
   "source": [
    "# Data variables\n",
    "max_msmtvar = len(ParamUpdater.meta_max_iter_scan)\n",
    "max_var = max(len(ParamUpdater.lambda_scan), len(ParamUpdater.msmt_per_qubit_scan))\n",
    "\n",
    "\n",
    "for prefix in ['NSL_tfloor', 'NSL_theight']:\n",
    "\n",
    "    if prefix[-5:] == 'floor':\n",
    "        max_prevar_floor = len(ParamUpdater.meta_truth_floor_scan)\n",
    "    if prefix[-5:] == 'eight':\n",
    "        max_prevar_floor = len(ParamUpdater.truth_step_scan)\n",
    "\n",
    "    for idx_noise_var in range(len(ParamUpdater.meta_noisevar_scan)):\n",
    "\n",
    "        for idx_var_dict in range(2):\n",
    "\n",
    "            full_data_matrix = np.zeros((max_prevar_floor, max_msmtvar, max_var, 2, 4))\n",
    "\n",
    "            for idx_prevar in range(max_prevar_floor):\n",
    "\n",
    "                for idx_msmt_var in range(max_msmtvar):\n",
    "\n",
    "                    macro_performance = []\n",
    "\n",
    "                    for idx_var in range(max_var):\n",
    "\n",
    "                        regime_ID = prefix + '_n_' + str(idx_noise_var) +'_vset_' + str(idx_var_dict)\n",
    "                        testcase_ID = regime_ID + '_t_' + str(idx_prevar) + '_m_' + str(idx_msmt_var)\n",
    "\n",
    "                        unique_ID = loadpath + testcase_ID + '_v_' + str(idx_var)\n",
    "\n",
    "                        PATHDICT[\"fle\"] = unique_ID\n",
    "\n",
    "                        perf_metrics = np.zeros((2, 4))\n",
    "                        \n",
    "                        try:\n",
    "                            qslamdata = np.load(path_to_file(PATHDICT, flag='q'))\n",
    "                            naivedata = np.load(path_to_file(PATHDICT, flag='n'))\n",
    "                        except:\n",
    "                            print \"Data filenot loaded. Unique ID:\", unique_ID\n",
    "                            macro_performance.append(perf_metrics)\n",
    "                            continue\n",
    "\n",
    "                        perf_metrics[:, 0] = np.asarray([Metric.original_err_metric(data[\"macro_residuals\"]) for data in [qslamdata, naivedata]])\n",
    "                        perf_metrics[:, 1] = np.asarray([Metric.err(data[\"macro_residuals\"]) for data in [qslamdata, naivedata]])\n",
    "                        perf_metrics[:, 2] = np.asarray([Metric.rms(data[\"macro_residuals\"]) for data in [qslamdata, naivedata]])\n",
    "                        perf_metrics[:, 3] = np.asarray([Metric.ssim(data)[0] for data in [qslamdata, naivedata]]) # returning ssim (raw) or deviations\n",
    "\n",
    "                        macro_performance.append(perf_metrics)\n",
    "\n",
    "\n",
    "                    full_data_matrix[idx_prevar, idx_msmt_var, :, :, :] = np.asarray(macro_performance)\n",
    "\n",
    "\n",
    "            datafile = './data/'+'RISK_' + regime_ID +'.npz'\n",
    "            np.savez(datafile, full_data_matrix=full_data_matrix)\n",
    "            \n",
    "            print \"Made data file:\", datafile\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
